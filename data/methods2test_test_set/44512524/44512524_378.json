{"test_class": {"identifier": "EnglishTokenizerTest", "superclass": "", "interfaces": "", "fields": [], "file": "storm/trident-ml/src/test/java/com/github/pmerienne/trident/ml/preprocessing/EnglishTokenizerTest.java"}, "test_case": {"identifier": "testTokenize", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n\tpublic void testTokenize() {\n\t\t// Given\n\t\tEnglishTokenizer tokenizer = new EnglishTokenizer();\n\t\tString text = \"I can't argue with some arguments on argus with argues\";\n\n\t\t// When\n\t\tList<String> actualTokens = tokenizer.tokenize(text);\n\n\t\t// Then\n\t\tList<String> expectedTokens = Arrays.asList(\"i\", \"can't\", \"argu\", \"some\", \"argument\", \"argu\", \"argu\");\n\t\tassertEquals(expectedTokens, actualTokens);\n\t}", "signature": "void testTokenize()", "full_signature": "@Test public void testTokenize()", "class_method_signature": "EnglishTokenizerTest.testTokenize()", "testcase": true, "constructor": false, "invocations": ["tokenize", "asList", "assertEquals"]}, "focal_class": {"identifier": "EnglishTokenizer", "superclass": "", "interfaces": "implements Serializable, TextTokenizer", "fields": [{"original_string": "private static final long serialVersionUID = -4307517944955017402L;", "modifier": "private static final", "type": "long", "declarator": "serialVersionUID = -4307517944955017402L", "var_name": "serialVersionUID"}, {"original_string": "private static final Log LOGGER = LogFactory.getLog(EnglishTokenizer.class);", "modifier": "private static final", "type": "Log", "declarator": "LOGGER = LogFactory.getLog(EnglishTokenizer.class)", "var_name": "LOGGER"}, {"original_string": "private final transient static Version LUCENE_VERSION = Version.LUCENE_36;", "modifier": "private final transient static", "type": "Version", "declarator": "LUCENE_VERSION = Version.LUCENE_36", "var_name": "LUCENE_VERSION"}, {"original_string": "protected List<String> stopWords = null;", "modifier": "protected", "type": "List<String>", "declarator": "stopWords = null", "var_name": "stopWords"}, {"original_string": "protected Set<String> stemExclusionsSet = new HashSet<String>();", "modifier": "protected", "type": "Set<String>", "declarator": "stemExclusionsSet = new HashSet<String>()", "var_name": "stemExclusionsSet"}, {"original_string": "private boolean nGram = false;", "modifier": "private", "type": "boolean", "declarator": "nGram = false", "var_name": "nGram"}, {"original_string": "private int minNGram = 2;", "modifier": "private", "type": "int", "declarator": "minNGram = 2", "var_name": "minNGram"}, {"original_string": "private int maxNGram = 2;", "modifier": "private", "type": "int", "declarator": "maxNGram = 2", "var_name": "maxNGram"}], "methods": [{"identifier": "EnglishTokenizer", "parameters": "()", "modifiers": "public", "return": "", "signature": " EnglishTokenizer()", "full_signature": "public  EnglishTokenizer()", "class_method_signature": "EnglishTokenizer.EnglishTokenizer()", "testcase": false, "constructor": true}, {"identifier": "EnglishTokenizer", "parameters": "(int minNGram, int maxNGram)", "modifiers": "public", "return": "", "signature": " EnglishTokenizer(int minNGram, int maxNGram)", "full_signature": "public  EnglishTokenizer(int minNGram, int maxNGram)", "class_method_signature": "EnglishTokenizer.EnglishTokenizer(int minNGram, int maxNGram)", "testcase": false, "constructor": true}, {"identifier": "EnglishTokenizer", "parameters": "(List<String> stopWords)", "modifiers": "public", "return": "", "signature": " EnglishTokenizer(List<String> stopWords)", "full_signature": "public  EnglishTokenizer(List<String> stopWords)", "class_method_signature": "EnglishTokenizer.EnglishTokenizer(List<String> stopWords)", "testcase": false, "constructor": true}, {"identifier": "EnglishTokenizer", "parameters": "(List<String> stopWords, Set<String> stemExclusionsSet)", "modifiers": "public", "return": "", "signature": " EnglishTokenizer(List<String> stopWords, Set<String> stemExclusionsSet)", "full_signature": "public  EnglishTokenizer(List<String> stopWords, Set<String> stemExclusionsSet)", "class_method_signature": "EnglishTokenizer.EnglishTokenizer(List<String> stopWords, Set<String> stemExclusionsSet)", "testcase": false, "constructor": true}, {"identifier": "tokenize", "parameters": "(String text)", "modifiers": "public", "return": "List<String>", "signature": "List<String> tokenize(String text)", "full_signature": "public List<String> tokenize(String text)", "class_method_signature": "EnglishTokenizer.tokenize(String text)", "testcase": false, "constructor": false}, {"identifier": "createTokenStream", "parameters": "(String text)", "modifiers": "protected", "return": "TokenStream", "signature": "TokenStream createTokenStream(String text)", "full_signature": "protected TokenStream createTokenStream(String text)", "class_method_signature": "EnglishTokenizer.createTokenStream(String text)", "testcase": false, "constructor": false}, {"identifier": "setNGram", "parameters": "(int minNGram, int maxNGram)", "modifiers": "public", "return": "void", "signature": "void setNGram(int minNGram, int maxNGram)", "full_signature": "public void setNGram(int minNGram, int maxNGram)", "class_method_signature": "EnglishTokenizer.setNGram(int minNGram, int maxNGram)", "testcase": false, "constructor": false}, {"identifier": "isnGram", "parameters": "()", "modifiers": "public", "return": "boolean", "signature": "boolean isnGram()", "full_signature": "public boolean isnGram()", "class_method_signature": "EnglishTokenizer.isnGram()", "testcase": false, "constructor": false}, {"identifier": "setnGram", "parameters": "(boolean nGram)", "modifiers": "public", "return": "void", "signature": "void setnGram(boolean nGram)", "full_signature": "public void setnGram(boolean nGram)", "class_method_signature": "EnglishTokenizer.setnGram(boolean nGram)", "testcase": false, "constructor": false}, {"identifier": "getMinNGram", "parameters": "()", "modifiers": "public", "return": "int", "signature": "int getMinNGram()", "full_signature": "public int getMinNGram()", "class_method_signature": "EnglishTokenizer.getMinNGram()", "testcase": false, "constructor": false}, {"identifier": "setMinNGram", "parameters": "(int minNGram)", "modifiers": "public", "return": "void", "signature": "void setMinNGram(int minNGram)", "full_signature": "public void setMinNGram(int minNGram)", "class_method_signature": "EnglishTokenizer.setMinNGram(int minNGram)", "testcase": false, "constructor": false}, {"identifier": "getMaxNGram", "parameters": "()", "modifiers": "public", "return": "int", "signature": "int getMaxNGram()", "full_signature": "public int getMaxNGram()", "class_method_signature": "EnglishTokenizer.getMaxNGram()", "testcase": false, "constructor": false}, {"identifier": "setMaxNGram", "parameters": "(int maxNGram)", "modifiers": "public", "return": "void", "signature": "void setMaxNGram(int maxNGram)", "full_signature": "public void setMaxNGram(int maxNGram)", "class_method_signature": "EnglishTokenizer.setMaxNGram(int maxNGram)", "testcase": false, "constructor": false}, {"identifier": "getStopWords", "parameters": "()", "modifiers": "public", "return": "List<String>", "signature": "List<String> getStopWords()", "full_signature": "public List<String> getStopWords()", "class_method_signature": "EnglishTokenizer.getStopWords()", "testcase": false, "constructor": false}, {"identifier": "setStopWords", "parameters": "(List<String> stopWords)", "modifiers": "public", "return": "void", "signature": "void setStopWords(List<String> stopWords)", "full_signature": "public void setStopWords(List<String> stopWords)", "class_method_signature": "EnglishTokenizer.setStopWords(List<String> stopWords)", "testcase": false, "constructor": false}, {"identifier": "setStemExclusionsSet", "parameters": "(Set<String> stemExclusionsSet)", "modifiers": "public", "return": "void", "signature": "void setStemExclusionsSet(Set<String> stemExclusionsSet)", "full_signature": "public void setStemExclusionsSet(Set<String> stemExclusionsSet)", "class_method_signature": "EnglishTokenizer.setStemExclusionsSet(Set<String> stemExclusionsSet)", "testcase": false, "constructor": false}, {"identifier": "getStemExclusionsSet", "parameters": "()", "modifiers": "public", "return": "Set<String>", "signature": "Set<String> getStemExclusionsSet()", "full_signature": "public Set<String> getStemExclusionsSet()", "class_method_signature": "EnglishTokenizer.getStemExclusionsSet()", "testcase": false, "constructor": false}], "file": "storm/trident-ml/src/main/java/com/github/pmerienne/trident/ml/preprocessing/EnglishTokenizer.java"}, "focal_method": {"identifier": "tokenize", "parameters": "(String text)", "modifiers": "public", "return": "List<String>", "body": "public List<String> tokenize(String text) {\n\t\tList<String> words = new ArrayList<String>();\n\t\tif (text != null && !text.isEmpty()) {\n\t\t\tTokenStream tokenStream = this.createTokenStream(text);\n\t\t\tCharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);\n\n\t\t\ttry {\n\t\t\t\twhile (tokenStream.incrementToken()) {\n\t\t\t\t\tString term = charTermAttribute.toString();\n\t\t\t\t\twords.add(term);\n\t\t\t\t}\n\t\t\t} catch (IOException ioe) {\n\t\t\t\tLOGGER.error(\"Unable to analyze text. Cause : \" + ioe.getMessage(), ioe);\n\t\t\t} finally {\n\t\t\t\ttry {\n\t\t\t\t\ttokenStream.end();\n\t\t\t\t\ttokenStream.close();\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\t// Can't do nothing!!\n\t\t\t\t\tLOGGER.error(\"Unable to close token stream : \" + e.getMessage());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn words;\n\t}", "signature": "List<String> tokenize(String text)", "full_signature": "public List<String> tokenize(String text)", "class_method_signature": "EnglishTokenizer.tokenize(String text)", "testcase": false, "constructor": false, "invocations": ["isEmpty", "createTokenStream", "addAttribute", "incrementToken", "toString", "add", "error", "getMessage", "end", "close", "error", "getMessage"]}, "repository": {"repo_id": 44512524, "url": "https://github.com/zqhxuyuan/bigdata", "language": "Java", "is_fork": false, "fork_count": 6, "stargazer_count": 8, "size": 91550, "license": "licensed"}}