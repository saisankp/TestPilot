{"test_class": {"identifier": "ActivationFunctionsTest", "superclass": "", "interfaces": "", "fields": [], "file": "deepnetts-core/src/test/java/deepnetts/net/layers/ActivationFunctionsTest.java"}, "test_case": {"identifier": "testTanh", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n    public void testTanh() {\n        float[] x = {-7.0f,  -6.9f,  -6.8f,  -6.7f,  -6.6f,  -6.5f,  -6.4f,  -6.3f,  -6.2f,  -6.1f,  -6.0f,  -5.9f,  -5.8f,  -5.7f,  -5.6f,  -5.5f,  -5.4f,  -5.3f,  -5.2f,  -5.1f,  -5.0f,  -4.9f,  -4.8f,  -4.7f,  -4.6f,  -4.5f,  -4.4f,  -4.3f,  -4.2f,  -4.1f,  -4.0f,  -3.9f,  -3.8f,  -3.7f,  -3.6f,  -3.5f,  -3.4f,  -3.3f,  -3.2f,  -3.1f,  -3.0f,  -2.9f,  -2.8f,  -2.7f,  -2.6f,  -2.5f,  -2.4f,  -2.3f,  -2.2f,  -2.1f,  -2.0f,  -1.9f,  -1.8f,  -1.7f,  -1.6f,  -1.5f,  -1.4f,  -1.3f,  -1.2f,  -1.1f,  -1.0f,  -0.9f,  -0.8f,  -0.7f,  -0.6f,  -0.5f,  -0.4f,  -0.3f,  -0.2f,  -0.1f,  0f,  0.1f,  0.2f,  0.3f,  0.4f,  0.5f,  0.6f,  0.7f,  0.8f,  0.9f,  1.0f,  1.1f,  1.2f,  1.3f,  1.4f,  1.5f,  1.6f,  1.7f,  1.8f,  1.9f,  2.0f,  2.1f,  2.2f,  2.3f,  2.4f,  2.5f,  2.6f,  2.7f,  2.8f,  2.9f,  3.0f,  3.1f,  3.2f,  3.3f,  3.4f,  3.5f,  3.6f,  3.7f,  3.8f,  3.9f,  4.0f,  4.1f,  4.2f,  4.3f,  4.4f,  4.5f,  4.6f,  4.7f,  4.8f,  4.9f,  5.0f,  5.1f,  5.2f,  5.3f,  5.4f,  5.5f,  5.6f,  5.7f,  5.8f,  5.9f,  6.0f,  6.1f,  6.2f,  6.3f,  6.4f,  6.5f,  6.6f,  6.7f,  6.8f,  6.9f,  7.0f};\n        float[] y = {-0.999998f,  -0.999998f,  -0.999997f,  -0.999997f,  -0.999996f,  -0.999995f,  -0.999994f,  -0.999993f,  -0.999992f,  -0.99999f,  -0.999988f,  -0.999985f,  -0.999982f,  -0.999978f,  -0.999973f,  -0.999967f,  -0.999959f,  -0.99995f,  -0.999939f,  -0.999926f,  -0.999909f,  -0.999889f,  -0.999865f,  -0.999835f,  -0.999798f,  -0.999753f,  -0.999699f,  -0.999632f,  -0.99955f,  -0.999451f,  -0.999329f,  -0.999181f,  -0.999f,  -0.998778f,  -0.998508f,  -0.998178f,  -0.997775f,  -0.997283f,  -0.996682f,  -0.995949f,  -0.995055f,  -0.993963f,  -0.992631f,  -0.991007f,  -0.989027f,  -0.986614f,  -0.983675f,  -0.980096f,  -0.975743f,  -0.970452f,  -0.964028f,  -0.956237f,  -0.946806f,  -0.935409f,  -0.921669f,  -0.905148f,  -0.885352f,  -0.861723f,  -0.833655f,  -0.800499f,  -0.761594f,  -0.716298f,  -0.664037f,  -0.604368f,  -0.53705f,  -0.462117f,  -0.379949f,  -0.291313f,  -0.197375f,  -0.099668f,  -2.4869e-14f,  0.099668f,  0.197375f,  0.291313f,  0.379949f,  0.462117f,  0.53705f,  0.604368f,  0.664037f,  0.716298f,  0.761594f,  0.800499f,  0.833655f,  0.861723f,  0.885352f,  0.905148f,  0.921669f,  0.935409f,  0.946806f,  0.956237f,  0.964028f,  0.970452f,  0.975743f,  0.980096f,  0.983675f,  0.986614f,  0.989027f,  0.991007f,  0.992631f,  0.993963f,  0.995055f,  0.995949f,  0.996682f,  0.997283f,  0.997775f,  0.998178f,  0.998508f,  0.998778f,  0.999f,  0.999181f,  0.999329f,  0.999451f,  0.99955f,  0.999632f,  0.999699f,  0.999753f,  0.999798f,  0.999835f,  0.999865f,  0.999889f,  0.999909f,  0.999926f,  0.999939f,  0.99995f,  0.999959f,  0.999967f,  0.999973f,  0.999978f,  0.999982f,  0.999985f,  0.999988f,  0.99999f,  0.999992f,  0.999993f,  0.999994f,  0.999995f,  0.999996f,  0.999997f,  0.999997f,  0.999998f,  0.999998f};\n                \n        for (int i = 0; i < x.length; i++) {\n            float expResult = y[i];\n            float result = ActivationFunctions.tanh(x[i]);\n            assertEquals(expResult, result, 1e-6);\n        }    \n    }", "signature": "void testTanh()", "full_signature": "@Test public void testTanh()", "class_method_signature": "ActivationFunctionsTest.testTanh()", "testcase": true, "constructor": false, "invocations": ["tanh", "assertEquals"]}, "focal_class": {"identifier": "ActivationFunctions", "superclass": "", "interfaces": "", "fields": [], "methods": [{"identifier": "ActivationFunctions", "parameters": "()", "modifiers": "private", "return": "", "signature": " ActivationFunctions()", "full_signature": "private  ActivationFunctions()", "class_method_signature": "ActivationFunctions.ActivationFunctions()", "testcase": false, "constructor": true}, {"identifier": "calc", "parameters": "(final ActivationType type, final float x)", "modifiers": "public static final", "return": "float", "signature": "float calc(final ActivationType type, final float x)", "full_signature": "public static final float calc(final ActivationType type, final float x)", "class_method_signature": "ActivationFunctions.calc(final ActivationType type, final float x)", "testcase": false, "constructor": false}, {"identifier": "prime", "parameters": "(ActivationType type, float y)", "modifiers": "public static final", "return": "float", "signature": "float prime(ActivationType type, float y)", "full_signature": "public static final float prime(ActivationType type, float y)", "class_method_signature": "ActivationFunctions.prime(ActivationType type, float y)", "testcase": false, "constructor": false}, {"identifier": "sigmoid", "parameters": "(final float x)", "modifiers": "public static final", "return": "float", "signature": "float sigmoid(final float x)", "full_signature": "public static final float sigmoid(final float x)", "class_method_signature": "ActivationFunctions.sigmoid(final float x)", "testcase": false, "constructor": false}, {"identifier": "sigmoidPrime", "parameters": "(final float y)", "modifiers": "public static final", "return": "float", "signature": "float sigmoidPrime(final float y)", "full_signature": "public static final float sigmoidPrime(final float y)", "class_method_signature": "ActivationFunctions.sigmoidPrime(final float y)", "testcase": false, "constructor": false}, {"identifier": "tanh", "parameters": "(final float x)", "modifiers": "public static final", "return": "float", "signature": "float tanh(final float x)", "full_signature": "public static final float tanh(final float x)", "class_method_signature": "ActivationFunctions.tanh(final float x)", "testcase": false, "constructor": false}, {"identifier": "tanhPrime", "parameters": "(final float y)", "modifiers": "public static final", "return": "float", "signature": "float tanhPrime(final float y)", "full_signature": "public static final float tanhPrime(final float y)", "class_method_signature": "ActivationFunctions.tanhPrime(final float y)", "testcase": false, "constructor": false}, {"identifier": "relu", "parameters": "(final float x)", "modifiers": "public static final", "return": "float", "signature": "float relu(final float x)", "full_signature": "public static final float relu(final float x)", "class_method_signature": "ActivationFunctions.relu(final float x)", "testcase": false, "constructor": false}, {"identifier": "reluPrime", "parameters": "(final float y)", "modifiers": "public static final", "return": "float", "signature": "float reluPrime(final float y)", "full_signature": "public static final float reluPrime(final float y)", "class_method_signature": "ActivationFunctions.reluPrime(final float y)", "testcase": false, "constructor": false}, {"identifier": "linear", "parameters": "(final float x)", "modifiers": "public static final", "return": "float", "signature": "float linear(final float x)", "full_signature": "public static final float linear(final float x)", "class_method_signature": "ActivationFunctions.linear(final float x)", "testcase": false, "constructor": false}, {"identifier": "linearPrime", "parameters": "(final float y)", "modifiers": "public static final", "return": "float", "signature": "float linearPrime(final float y)", "full_signature": "public static final float linearPrime(final float y)", "class_method_signature": "ActivationFunctions.linearPrime(final float y)", "testcase": false, "constructor": false}], "file": "deepnetts-core/src/main/java/deepnetts/net/layers/ActivationFunctions.java"}, "focal_method": {"identifier": "tanh", "parameters": "(final float x)", "modifiers": "public static final", "return": "float", "body": "public static final float tanh(final float x) {\n       // x = x*2/3;\n       // float a=1.7159;\n       final float e2x = (float)Math.exp(2*x);   \n       return (e2x-1) / (e2x+1); // calculate tanh \n    }", "signature": "float tanh(final float x)", "full_signature": "public static final float tanh(final float x)", "class_method_signature": "ActivationFunctions.tanh(final float x)", "testcase": false, "constructor": false, "invocations": ["exp"]}, "repository": {"repo_id": 108833646, "url": "https://github.com/sevarac/deepnetts", "language": "Java", "is_fork": false, "fork_count": 3, "stargazer_count": 8, "size": 5220, "license": "licensed"}}