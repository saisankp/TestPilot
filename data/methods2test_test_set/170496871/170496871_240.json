{"test_class": {"identifier": "MaxAbsScalerTrainerTest", "superclass": "extends TrainerTest", "interfaces": "", "fields": [], "file": "modules/ml/src/test/java/org/apache/ignite/ml/preprocessing/maxabsscaling/MaxAbsScalerTrainerTest.java"}, "test_case": {"identifier": "testFit", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n    public void testFit() {\n        Map<Integer, Vector> data = new HashMap<>();\n        data.put(1, VectorUtils.of(2, -4, 1));\n        data.put(2, VectorUtils.of(1, -8, 22));\n        data.put(3, VectorUtils.of(-4, 10, 100));\n        data.put(4, VectorUtils.of(0, 22, 300));\n\n        DatasetBuilder<Integer, Vector> datasetBuilder = new LocalDatasetBuilder<>(data, parts);\n\n        final Vectorizer<Integer, Vector, Integer, Double> vectorizer = new DummyVectorizer<>(0, 1, 2);\n\n        MaxAbsScalerTrainer<Integer, Vector> standardizationTrainer = new MaxAbsScalerTrainer<>();\n\n        MaxAbsScalerPreprocessor<Integer, Vector> preprocessor = standardizationTrainer.fit(\n            TestUtils.testEnvBuilder(),\n            datasetBuilder,\n            vectorizer\n        );\n\n        assertArrayEquals(new double[] {4, 22, 300}, preprocessor.getMaxAbs(), 1e-8);\n    }", "signature": "void testFit()", "full_signature": "@Test public void testFit()", "class_method_signature": "MaxAbsScalerTrainerTest.testFit()", "testcase": true, "constructor": false, "invocations": ["put", "of", "put", "of", "put", "of", "put", "of", "fit", "testEnvBuilder", "assertArrayEquals", "getMaxAbs"]}, "focal_class": {"identifier": "MaxAbsScalerTrainer", "superclass": "", "interfaces": "implements PreprocessingTrainer<K, V>", "fields": [], "methods": [{"identifier": "fit", "parameters": "(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "modifiers": "@Override public", "return": "MaxAbsScalerPreprocessor<K, V>", "signature": "MaxAbsScalerPreprocessor<K, V> fit(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "full_signature": "@Override public MaxAbsScalerPreprocessor<K, V> fit(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "class_method_signature": "MaxAbsScalerTrainer.fit(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "testcase": false, "constructor": false}], "file": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/maxabsscaling/MaxAbsScalerTrainer.java"}, "focal_method": {"identifier": "fit", "parameters": "(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "modifiers": "@Override public", "return": "MaxAbsScalerPreprocessor<K, V>", "body": "@Override public MaxAbsScalerPreprocessor<K, V> fit(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor) {\n        try (Dataset<EmptyContext, MaxAbsScalerPartitionData> dataset = datasetBuilder.build(\n            envBuilder,\n            (env, upstream, upstreamSize) -> new EmptyContext(),\n            (env, upstream, upstreamSize, ctx) -> {\n                double[] maxAbs = null;\n\n                while (upstream.hasNext()) {\n                    UpstreamEntry<K, V> entity = upstream.next();\n                    LabeledVector row = basePreprocessor.apply(entity.getKey(), entity.getValue());\n\n                    if (maxAbs == null) {\n                        maxAbs = new double[row.size()];\n                        for (int i = 0; i < maxAbs.length; i++)\n                            maxAbs[i] = .0;\n                    }\n                    else\n                        assert maxAbs.length == row.size() : \"Base preprocessor must return exactly \" + maxAbs.length\n                            + \" features\";\n\n                    for (int i = 0; i < row.size(); i++) {\n                        if (Math.abs(row.get(i)) > Math.abs(maxAbs[i]))\n                            maxAbs[i] = Math.abs(row.get(i));\n                    }\n                }\n                return new MaxAbsScalerPartitionData(maxAbs);\n            }, learningEnvironment(basePreprocessor)\n        )) {\n            double[] maxAbs = dataset.compute(MaxAbsScalerPartitionData::getMaxAbs,\n                (a, b) -> {\n                    if (a == null)\n                        return b;\n\n                    if (b == null)\n                        return a;\n\n                    double[] res = new double[a.length];\n\n                    for (int i = 0; i < res.length; i++)\n                        res[i] = Math.max(Math.abs(a[i]), Math.abs(b[i]));\n\n                    return res;\n                });\n            return new MaxAbsScalerPreprocessor<>(maxAbs, basePreprocessor);\n        }\n        catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }", "signature": "MaxAbsScalerPreprocessor<K, V> fit(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "full_signature": "@Override public MaxAbsScalerPreprocessor<K, V> fit(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "class_method_signature": "MaxAbsScalerTrainer.fit(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "testcase": false, "constructor": false, "invocations": ["build", "hasNext", "next", "apply", "getKey", "getValue", "size", "size", "size", "abs", "get", "abs", "abs", "get", "learningEnvironment", "compute", "max", "abs", "abs"]}, "repository": {"repo_id": 170496871, "url": "https://github.com/gridgain/gridgain", "stars": 46, "created": "2/13/2019 11:31:35 AM +00:00", "updates": "2020-01-27T16:02:24+00:00", "fork": "False", "license": "licensed"}}