{"test_class": {"identifier": "IndirectBigQueryOutputCommitterTest", "superclass": "", "interfaces": "", "fields": [{"original_string": "private static final String TEST_PROJECT_ID = \"domain:project\";", "modifier": "private static final", "type": "String", "declarator": "TEST_PROJECT_ID = \"domain:project\"", "var_name": "TEST_PROJECT_ID"}, {"original_string": "private static final String TEST_DATASET_ID = \"dataset\";", "modifier": "private static final", "type": "String", "declarator": "TEST_DATASET_ID = \"dataset\"", "var_name": "TEST_DATASET_ID"}, {"original_string": "private static final String TEST_TABLE_ID = \"table\";", "modifier": "private static final", "type": "String", "declarator": "TEST_TABLE_ID = \"table\"", "var_name": "TEST_TABLE_ID"}, {"original_string": "private static final String QUALIFIED_TEST_TABLE_ID =\n      String.format(\"%s:%s.%s\", TEST_PROJECT_ID, TEST_DATASET_ID, TEST_TABLE_ID);", "modifier": "private static final", "type": "String", "declarator": "QUALIFIED_TEST_TABLE_ID =\n      String.format(\"%s:%s.%s\", TEST_PROJECT_ID, TEST_DATASET_ID, TEST_TABLE_ID)", "var_name": "QUALIFIED_TEST_TABLE_ID"}, {"original_string": "private static final BigQueryTimePartitioning TEST_TIME_PARTITIONING =\n      BigQueryTimePartitioning.wrap(new TimePartitioning().setType(\"DAY\"));", "modifier": "private static final", "type": "BigQueryTimePartitioning", "declarator": "TEST_TIME_PARTITIONING =\n      BigQueryTimePartitioning.wrap(new TimePartitioning().setType(\"DAY\"))", "var_name": "TEST_TIME_PARTITIONING"}, {"original_string": "private static final BigQueryFileFormat TEST_FILE_FORMAT =\n      BigQueryFileFormat.NEWLINE_DELIMITED_JSON;", "modifier": "private static final", "type": "BigQueryFileFormat", "declarator": "TEST_FILE_FORMAT =\n      BigQueryFileFormat.NEWLINE_DELIMITED_JSON", "var_name": "TEST_FILE_FORMAT"}, {"original_string": "private static final String TEST_WRITE_DISPOSITION =\n      BigQueryConfiguration.OUTPUT_TABLE_WRITE_DISPOSITION.getDefault();", "modifier": "private static final", "type": "String", "declarator": "TEST_WRITE_DISPOSITION =\n      BigQueryConfiguration.OUTPUT_TABLE_WRITE_DISPOSITION.getDefault()", "var_name": "TEST_WRITE_DISPOSITION"}, {"original_string": "private static final String TEST_CREATE_DISPOSITION =\n      BigQueryConfiguration.OUTPUT_TABLE_CREATE_DISPOSITION.getDefault();", "modifier": "private static final", "type": "String", "declarator": "TEST_CREATE_DISPOSITION =\n      BigQueryConfiguration.OUTPUT_TABLE_CREATE_DISPOSITION.getDefault()", "var_name": "TEST_CREATE_DISPOSITION"}, {"original_string": "@SuppressWarnings(\"rawtypes\")\n  private static final Class<? extends FileOutputFormat> TEST_OUTPUT_CLASS = TextOutputFormat.class;", "modifier": "@SuppressWarnings(\"rawtypes\")\n  private static final", "type": "Class<? extends FileOutputFormat>", "declarator": "TEST_OUTPUT_CLASS = TextOutputFormat.class", "var_name": "TEST_OUTPUT_CLASS"}, {"original_string": "private static final BigQueryTableSchema TEST_TABLE_SCHEMA =\n      BigQueryTableSchema.wrap(\n          new TableSchema()\n              .setFields(\n                  ImmutableList.of(\n                      new TableFieldSchema().setName(\"Word\").setType(\"STRING\"),\n                      new TableFieldSchema().setName(\"Count\").setType(\"INTEGER\"))));", "modifier": "private static final", "type": "BigQueryTableSchema", "declarator": "TEST_TABLE_SCHEMA =\n      BigQueryTableSchema.wrap(\n          new TableSchema()\n              .setFields(\n                  ImmutableList.of(\n                      new TableFieldSchema().setName(\"Word\").setType(\"STRING\"),\n                      new TableFieldSchema().setName(\"Count\").setType(\"INTEGER\"))))", "var_name": "TEST_TABLE_SCHEMA"}, {"original_string": "private static final String TEST_KMS_KEY_NAME =\n      \"projects/domain:project/locations/us-west1/keyRings/ring-1/cryptoKeys/key-1\";", "modifier": "private static final", "type": "String", "declarator": "TEST_KMS_KEY_NAME =\n      \"projects/domain:project/locations/us-west1/keyRings/ring-1/cryptoKeys/key-1\"", "var_name": "TEST_KMS_KEY_NAME"}, {"original_string": "private static final TaskAttemptID TEST_TASK_ATTEMPT_ID =\n      new TaskAttemptID(new TaskID(\"sample_task\", 100, false, 200), 1);", "modifier": "private static final", "type": "TaskAttemptID", "declarator": "TEST_TASK_ATTEMPT_ID =\n      new TaskAttemptID(new TaskID(\"sample_task\", 100, false, 200), 1)", "var_name": "TEST_TASK_ATTEMPT_ID"}, {"original_string": "private static final String TEST_OUTPUT_PATH_STRING = \"gs://test_bucket/test_directory/\";", "modifier": "private static final", "type": "String", "declarator": "TEST_OUTPUT_PATH_STRING = \"gs://test_bucket/test_directory/\"", "var_name": "TEST_OUTPUT_PATH_STRING"}, {"original_string": "private static final String TEST_OUTPUT_FILE_STRING = TEST_OUTPUT_PATH_STRING + \"test_file\";", "modifier": "private static final", "type": "String", "declarator": "TEST_OUTPUT_FILE_STRING = TEST_OUTPUT_PATH_STRING + \"test_file\"", "var_name": "TEST_OUTPUT_FILE_STRING"}, {"original_string": "private InMemoryGoogleHadoopFileSystem ghfs;", "modifier": "private", "type": "InMemoryGoogleHadoopFileSystem", "declarator": "ghfs", "var_name": "ghfs"}, {"original_string": "private TableReference outputTableRef;", "modifier": "private", "type": "TableReference", "declarator": "outputTableRef", "var_name": "outputTableRef"}, {"original_string": "private Configuration conf;", "modifier": "private", "type": "Configuration", "declarator": "conf", "var_name": "conf"}, {"original_string": "private Path outputPath;", "modifier": "private", "type": "Path", "declarator": "outputPath", "var_name": "outputPath"}, {"original_string": "private Path outputSampleFilePath;", "modifier": "private", "type": "Path", "declarator": "outputSampleFilePath", "var_name": "outputSampleFilePath"}, {"original_string": "private Job job;", "modifier": "private", "type": "Job", "declarator": "job", "var_name": "job"}, {"original_string": "private IndirectBigQueryOutputCommitter committer;", "modifier": "private", "type": "IndirectBigQueryOutputCommitter", "declarator": "committer", "var_name": "committer"}, {"original_string": "@Mock private BigQueryHelper mockBigQueryHelper;", "modifier": "@Mock private", "type": "BigQueryHelper", "declarator": "mockBigQueryHelper", "var_name": "mockBigQueryHelper"}, {"original_string": "@Mock private TaskAttemptContext mockTaskAttemptContext;", "modifier": "@Mock private", "type": "TaskAttemptContext", "declarator": "mockTaskAttemptContext", "var_name": "mockTaskAttemptContext"}, {"original_string": "@Mock private OutputCommitter mockCommitter;", "modifier": "@Mock private", "type": "OutputCommitter", "declarator": "mockCommitter", "var_name": "mockCommitter"}], "file": "bigquery/src/test/java/com/google/cloud/hadoop/io/bigquery/output/IndirectBigQueryOutputCommitterTest.java"}, "test_case": {"identifier": "testCommitJob", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n  public void testCommitJob() throws Exception {\n    // Setup the sample directory.\n    generateSampleFiles();\n\n    committer.commitJob(job);\n\n    // Setup a captor for the GCS paths argument\n    @SuppressWarnings({\"rawtypes\", \"unchecked\", \"cast\"})\n    // Class<List> is neither a sub/supertype of Class<List<String>>, the latter doesn't even exist.\n    Class<List<String>> listClass = (Class<List<String>>) (Class) List.class;\n    ArgumentCaptor<List<String>> gcsOutputFileCaptor = ArgumentCaptor.forClass(listClass);\n\n    // Verify we're making the BigQuery import call.\n    verify(mockBigQueryHelper)\n        .importFromGcs(\n            eq(TEST_PROJECT_ID),\n            eq(outputTableRef),\n            eq(TEST_TABLE_SCHEMA.get()),\n            eq(TEST_TIME_PARTITIONING.get()),\n            eq(TEST_KMS_KEY_NAME),\n            eq(TEST_FILE_FORMAT),\n            eq(TEST_CREATE_DISPOSITION),\n            eq(TEST_WRITE_DISPOSITION),\n            gcsOutputFileCaptor.capture(),\n            eq(true));\n\n    // Verify the delegate is being called.\n    verify(mockCommitter).commitJob(eq(job));\n\n    // Assert the passed files contains our sample file.\n    assertThat(gcsOutputFileCaptor.getValue()).contains(TEST_OUTPUT_FILE_STRING);\n  }", "signature": "void testCommitJob()", "full_signature": "@Test public void testCommitJob()", "class_method_signature": "IndirectBigQueryOutputCommitterTest.testCommitJob()", "testcase": true, "constructor": false, "invocations": ["generateSampleFiles", "commitJob", "forClass", "importFromGcs", "verify", "eq", "eq", "eq", "get", "eq", "get", "eq", "eq", "eq", "eq", "capture", "eq", "commitJob", "verify", "eq", "contains", "assertThat", "getValue"]}, "focal_class": {"identifier": "IndirectBigQueryOutputCommitter", "superclass": "extends ForwardingBigQueryFileOutputCommitter", "interfaces": "", "fields": [], "methods": [{"identifier": "IndirectBigQueryOutputCommitter", "parameters": "(TaskAttemptContext context, OutputCommitter delegate)", "modifiers": "public", "return": "", "signature": " IndirectBigQueryOutputCommitter(TaskAttemptContext context, OutputCommitter delegate)", "full_signature": "public  IndirectBigQueryOutputCommitter(TaskAttemptContext context, OutputCommitter delegate)", "class_method_signature": "IndirectBigQueryOutputCommitter.IndirectBigQueryOutputCommitter(TaskAttemptContext context, OutputCommitter delegate)", "testcase": false, "constructor": true}, {"identifier": "commitJob", "parameters": "(JobContext context)", "modifiers": "@Override public", "return": "void", "signature": "void commitJob(JobContext context)", "full_signature": "@Override public void commitJob(JobContext context)", "class_method_signature": "IndirectBigQueryOutputCommitter.commitJob(JobContext context)", "testcase": false, "constructor": false}, {"identifier": "abortJob", "parameters": "(JobContext context, State state)", "modifiers": "@Override public", "return": "void", "signature": "void abortJob(JobContext context, State state)", "full_signature": "@Override public void abortJob(JobContext context, State state)", "class_method_signature": "IndirectBigQueryOutputCommitter.abortJob(JobContext context, State state)", "testcase": false, "constructor": false}], "file": "bigquery/src/main/java/com/google/cloud/hadoop/io/bigquery/output/IndirectBigQueryOutputCommitter.java"}, "focal_method": {"identifier": "commitJob", "parameters": "(JobContext context)", "modifiers": "@Override public", "return": "void", "body": "@Override\n  public void commitJob(JobContext context) throws IOException {\n    super.commitJob(context);\n\n    // Get the destination configuration information.\n    Configuration conf = context.getConfiguration();\n    TableReference destTable = BigQueryOutputConfiguration.getTableReference(conf);\n    String jobProjectId = BigQueryOutputConfiguration.getJobProjectId(conf);\n    String writeDisposition = BigQueryOutputConfiguration.getWriteDisposition(conf);\n    String createDisposition = BigQueryOutputConfiguration.getCreateDisposition(conf);\n    Optional<BigQueryTableSchema> destSchema = BigQueryOutputConfiguration.getTableSchema(conf);\n    Optional<BigQueryTimePartitioning> timePartitioning =\n        BigQueryOutputConfiguration.getTablePartitioning(conf);\n    String kmsKeyName = BigQueryOutputConfiguration.getKmsKeyName(conf);\n    BigQueryFileFormat outputFileFormat = BigQueryOutputConfiguration.getFileFormat(conf);\n    List<String> sourceUris = getOutputFileURIs();\n\n    try {\n      getBigQueryHelper()\n          .importFromGcs(\n              jobProjectId,\n              destTable,\n              destSchema.isPresent() ? destSchema.get().get() : null,\n              timePartitioning.isPresent() ? timePartitioning.get().get() : null,\n              kmsKeyName,\n              outputFileFormat,\n              createDisposition,\n              writeDisposition,\n              sourceUris,\n              true);\n    } catch (InterruptedException e) {\n      Thread.currentThread().interrupt();\n      throw new IOException(\"Failed to import GCS into BigQuery\", e);\n    }\n\n    cleanup(context);\n  }", "signature": "void commitJob(JobContext context)", "full_signature": "@Override public void commitJob(JobContext context)", "class_method_signature": "IndirectBigQueryOutputCommitter.commitJob(JobContext context)", "testcase": false, "constructor": false, "invocations": ["commitJob", "getConfiguration", "getTableReference", "getJobProjectId", "getWriteDisposition", "getCreateDisposition", "getTableSchema", "getTablePartitioning", "getKmsKeyName", "getFileFormat", "getOutputFileURIs", "importFromGcs", "getBigQueryHelper", "isPresent", "get", "get", "isPresent", "get", "get", "interrupt", "currentThread", "cleanup"]}, "repository": {"repo_id": 19684359, "url": "https://github.com/GoogleCloudDataproc/bigdata-interop", "stars": 178, "created": "5/12/2014 3:11:55 AM +00:00", "updates": "2020-01-23T23:10:40+00:00", "fork": "False", "license": "licensed"}}