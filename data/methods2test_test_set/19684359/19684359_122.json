{"test_class": {"identifier": "DirectBigQueryRecordReaderTest", "superclass": "", "interfaces": "", "fields": [{"original_string": "private static final String RAW_SCHEMA =\n      \"{\\\"type\\\": \\\"record\\\", \\\"name\\\": \\\"__root__\\\", \\\"fields\\\": [{\\\"name\\\": \\\"f0_\\\", \\\"type\\\":\"\n          + \" [\\\"null\\\", \\\"long\\\"]}]}\";", "modifier": "private static final", "type": "String", "declarator": "RAW_SCHEMA =\n      \"{\\\"type\\\": \\\"record\\\", \\\"name\\\": \\\"__root__\\\", \\\"fields\\\": [{\\\"name\\\": \\\"f0_\\\", \\\"type\\\":\"\n          + \" [\\\"null\\\", \\\"long\\\"]}]}\"", "var_name": "RAW_SCHEMA"}, {"original_string": "private Schema parsedSchema;", "modifier": "private", "type": "Schema", "declarator": "parsedSchema", "var_name": "parsedSchema"}, {"original_string": "private static final List<ReadRowsResponse> RESPONSES_123 =\n      ImmutableList.of(\n          ReadRowsResponse.newBuilder()\n              .setAvroRows(\n                  AvroRows.newBuilder()\n                      .setRowCount(2)\n                      .setSerializedBinaryRows(\n                          ByteString.copyFrom(new byte[] {2, 2, 2, 4}))) // 1, 2\n              .build(),\n          ReadRowsResponse.newBuilder()\n              .setAvroRows(\n                  AvroRows.newBuilder()\n                      .setRowCount(1)\n                      .setSerializedBinaryRows(ByteString.copyFrom(new byte[] {2, 6}))) // 3\n              .build());", "modifier": "private static final", "type": "List<ReadRowsResponse>", "declarator": "RESPONSES_123 =\n      ImmutableList.of(\n          ReadRowsResponse.newBuilder()\n              .setAvroRows(\n                  AvroRows.newBuilder()\n                      .setRowCount(2)\n                      .setSerializedBinaryRows(\n                          ByteString.copyFrom(new byte[] {2, 2, 2, 4}))) // 1, 2\n              .build(),\n          ReadRowsResponse.newBuilder()\n              .setAvroRows(\n                  AvroRows.newBuilder()\n                      .setRowCount(1)\n                      .setSerializedBinaryRows(ByteString.copyFrom(new byte[] {2, 6}))) // 3\n              .build())", "var_name": "RESPONSES_123"}, {"original_string": "private DirectBigQueryInputSplit split = new DirectBigQueryInputSplit(\"session\", RAW_SCHEMA, 5);", "modifier": "private", "type": "DirectBigQueryInputSplit", "declarator": "split = new DirectBigQueryInputSplit(\"session\", RAW_SCHEMA, 5)", "var_name": "split"}, {"original_string": "private static final Stream STREAM = Stream.newBuilder().setName(\"session\").build();", "modifier": "private static final", "type": "Stream", "declarator": "STREAM = Stream.newBuilder().setName(\"session\").build()", "var_name": "STREAM"}, {"original_string": "@Mock private BigQueryStorageClient bqClient;", "modifier": "@Mock private", "type": "BigQueryStorageClient", "declarator": "bqClient", "var_name": "bqClient"}, {"original_string": "@Mock private ServerStreamingCallable<ReadRowsRequest, ReadRowsResponse> readRows;", "modifier": "@Mock private", "type": "ServerStreamingCallable<ReadRowsRequest, ReadRowsResponse>", "declarator": "readRows", "var_name": "readRows"}, {"original_string": "@Mock private TaskAttemptContext taskContext;", "modifier": "@Mock private", "type": "TaskAttemptContext", "declarator": "taskContext", "var_name": "taskContext"}, {"original_string": "@Mock private ServerStream<ReadRowsResponse> rowsStream;", "modifier": "@Mock private", "type": "ServerStream<ReadRowsResponse>", "declarator": "rowsStream", "var_name": "rowsStream"}, {"original_string": "private DirectBigQueryRecordReader reader;", "modifier": "private", "type": "DirectBigQueryRecordReader", "declarator": "reader", "var_name": "reader"}], "file": "bigquery/src/test/java/com/google/cloud/hadoop/io/bigquery/DirectBigQueryRecordReaderTest.java"}, "test_case": {"identifier": "testInitialize", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n  public void testInitialize() throws Exception {\n    initialize();\n  }", "signature": "void testInitialize()", "full_signature": "@Test public void testInitialize()", "class_method_signature": "DirectBigQueryRecordReaderTest.testInitialize()", "testcase": true, "constructor": false, "invocations": ["initialize"]}, "focal_class": {"identifier": "DirectBigQueryRecordReader", "superclass": "extends RecordReader<NullWritable, GenericRecord>", "interfaces": "", "fields": [{"original_string": "private Schema schema;", "modifier": "private", "type": "Schema", "declarator": "schema", "var_name": "schema"}, {"original_string": "private Stream stream;", "modifier": "private", "type": "Stream", "declarator": "stream", "var_name": "stream"}, {"original_string": "private Parser parser = new Parser();", "modifier": "private", "type": "Parser", "declarator": "parser = new Parser()", "var_name": "parser"}, {"original_string": "private GenericRecord current;", "modifier": "private", "type": "GenericRecord", "declarator": "current", "var_name": "current"}, {"original_string": "private boolean finalized;", "modifier": "private", "type": "boolean", "declarator": "finalized", "var_name": "finalized"}, {"original_string": "private long limit;", "modifier": "private", "type": "long", "declarator": "limit", "var_name": "limit"}, {"original_string": "private long idx;", "modifier": "private", "type": "long", "declarator": "idx", "var_name": "idx"}, {"original_string": "private BigQueryStorageClient client;", "modifier": "private", "type": "BigQueryStorageClient", "declarator": "client", "var_name": "client"}, {"original_string": "private Iterator<ReadRowsResponse> responseIterator;", "modifier": "private", "type": "Iterator<ReadRowsResponse>", "declarator": "responseIterator", "var_name": "responseIterator"}, {"original_string": "private Iterator<GenericRecord> recordIterator;", "modifier": "private", "type": "Iterator<GenericRecord>", "declarator": "recordIterator", "var_name": "recordIterator"}], "methods": [{"identifier": "initialize", "parameters": "(InputSplit genericSplit, TaskAttemptContext context)", "modifiers": "@Override public", "return": "void", "signature": "void initialize(InputSplit genericSplit, TaskAttemptContext context)", "full_signature": "@Override public void initialize(InputSplit genericSplit, TaskAttemptContext context)", "class_method_signature": "DirectBigQueryRecordReader.initialize(InputSplit genericSplit, TaskAttemptContext context)", "testcase": false, "constructor": false}, {"identifier": "nextKeyValue", "parameters": "()", "modifiers": "@Override public", "return": "boolean", "signature": "boolean nextKeyValue()", "full_signature": "@Override public boolean nextKeyValue()", "class_method_signature": "DirectBigQueryRecordReader.nextKeyValue()", "testcase": false, "constructor": false}, {"identifier": "getCurrentKey", "parameters": "()", "modifiers": "@Override public", "return": "NullWritable", "signature": "NullWritable getCurrentKey()", "full_signature": "@Override public NullWritable getCurrentKey()", "class_method_signature": "DirectBigQueryRecordReader.getCurrentKey()", "testcase": false, "constructor": false}, {"identifier": "getCurrentValue", "parameters": "()", "modifiers": "@Override public", "return": "GenericRecord", "signature": "GenericRecord getCurrentValue()", "full_signature": "@Override public GenericRecord getCurrentValue()", "class_method_signature": "DirectBigQueryRecordReader.getCurrentValue()", "testcase": false, "constructor": false}, {"identifier": "getProgress", "parameters": "()", "modifiers": "@Override public", "return": "float", "signature": "float getProgress()", "full_signature": "@Override public float getProgress()", "class_method_signature": "DirectBigQueryRecordReader.getProgress()", "testcase": false, "constructor": false}, {"identifier": "close", "parameters": "()", "modifiers": "@Override public", "return": "void", "signature": "void close()", "full_signature": "@Override public void close()", "class_method_signature": "DirectBigQueryRecordReader.close()", "testcase": false, "constructor": false}, {"identifier": "getClient", "parameters": "(Configuration conf)", "modifiers": "protected", "return": "BigQueryStorageClient", "signature": "BigQueryStorageClient getClient(Configuration conf)", "full_signature": "protected BigQueryStorageClient getClient(Configuration conf)", "class_method_signature": "DirectBigQueryRecordReader.getClient(Configuration conf)", "testcase": false, "constructor": false}], "file": "bigquery/src/main/java/com/google/cloud/hadoop/io/bigquery/DirectBigQueryRecordReader.java"}, "focal_method": {"identifier": "initialize", "parameters": "(InputSplit genericSplit, TaskAttemptContext context)", "modifiers": "@Override public", "return": "void", "body": "@Override\n  public void initialize(InputSplit genericSplit, TaskAttemptContext context) throws IOException {\n    DirectBigQueryInputSplit split = (DirectBigQueryInputSplit) genericSplit;\n    schema = parser.parse(checkNotNull(split.getSchema(), \"schema\"));\n\n    stream = Stream.newBuilder().setName(checkNotNull(split.getName(), \"name\")).build();\n    ReadRowsRequest request =\n        ReadRowsRequest.newBuilder()\n            .setReadPosition(StreamPosition.newBuilder().setStream(stream).build())\n            .build();\n\n    client = getClient(context.getConfiguration());\n    responseIterator = client.readRowsCallable().call(request).iterator();\n    recordIterator = Collections.emptyIterator();\n\n    limit = split.getLimit();\n    idx = 0;\n    finalized = false;\n  }", "signature": "void initialize(InputSplit genericSplit, TaskAttemptContext context)", "full_signature": "@Override public void initialize(InputSplit genericSplit, TaskAttemptContext context)", "class_method_signature": "DirectBigQueryRecordReader.initialize(InputSplit genericSplit, TaskAttemptContext context)", "testcase": false, "constructor": false, "invocations": ["parse", "checkNotNull", "getSchema", "build", "setName", "newBuilder", "checkNotNull", "getName", "build", "setReadPosition", "newBuilder", "build", "setStream", "newBuilder", "getClient", "getConfiguration", "iterator", "call", "readRowsCallable", "emptyIterator", "getLimit"]}, "repository": {"repo_id": 19684359, "url": "https://github.com/GoogleCloudDataproc/bigdata-interop", "stars": 178, "created": "5/12/2014 3:11:55 AM +00:00", "updates": "2020-01-23T23:10:40+00:00", "fork": "False", "license": "licensed"}}