{"test_class": {"identifier": "MinMaxScalerTrainerTest", "superclass": "extends TrainerTest", "interfaces": "", "fields": [], "file": "modules/ml/src/test/java/org/apache/ignite/ml/preprocessing/minmaxscaling/MinMaxScalerTrainerTest.java"}, "test_case": {"identifier": "testFit", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n    public void testFit() {\n        Map<Integer, Vector> data = new HashMap<>();\n        data.put(1, VectorUtils.of(2, 4, 1));\n        data.put(2, VectorUtils.of(1, 8, 22));\n        data.put(3, VectorUtils.of(4, 10, 100));\n        data.put(4, VectorUtils.of(0, 22, 300));\n\n        DatasetBuilder<Integer, Vector> datasetBuilder = new LocalDatasetBuilder<>(data, parts);\n\n        final Vectorizer<Integer, Vector, Integer, Double> vectorizer = new DummyVectorizer<>(0, 1, 2);\n\n        MinMaxScalerTrainer<Integer, Vector> standardizationTrainer = new MinMaxScalerTrainer<>();\n\n        MinMaxScalerPreprocessor<Integer, Vector> preprocessor = standardizationTrainer.fit(\n            TestUtils.testEnvBuilder(),\n            datasetBuilder,\n            vectorizer\n        );\n\n        assertArrayEquals(new double[] {0, 4, 1}, preprocessor.getMin(), 1e-8);\n        assertArrayEquals(new double[] {4, 22, 300}, preprocessor.getMax(), 1e-8);\n    }", "signature": "void testFit()", "full_signature": "@Test public void testFit()", "class_method_signature": "MinMaxScalerTrainerTest.testFit()", "testcase": true, "constructor": false, "invocations": ["put", "of", "put", "of", "put", "of", "put", "of", "fit", "testEnvBuilder", "assertArrayEquals", "getMin", "assertArrayEquals", "getMax"]}, "focal_class": {"identifier": "MinMaxScalerTrainer", "superclass": "", "interfaces": "implements PreprocessingTrainer<K, V>", "fields": [], "methods": [{"identifier": "fit", "parameters": "(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "modifiers": "@Override public", "return": "MinMaxScalerPreprocessor<K, V>", "signature": "MinMaxScalerPreprocessor<K, V> fit(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "full_signature": "@Override public MinMaxScalerPreprocessor<K, V> fit(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "class_method_signature": "MinMaxScalerTrainer.fit(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "testcase": false, "constructor": false}], "file": "modules/ml/src/main/java/org/apache/ignite/ml/preprocessing/minmaxscaling/MinMaxScalerTrainer.java"}, "focal_method": {"identifier": "fit", "parameters": "(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "modifiers": "@Override public", "return": "MinMaxScalerPreprocessor<K, V>", "body": "@Override public MinMaxScalerPreprocessor<K, V> fit(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor) {\n        PartitionContextBuilder<K, V, EmptyContext> ctxBuilder = (env, upstream, upstreamSize) -> new EmptyContext();\n        try (Dataset<EmptyContext, MinMaxScalerPartitionData> dataset = datasetBuilder.build(\n            envBuilder,\n            ctxBuilder,\n            (env, upstream, upstreamSize, ctx) -> {\n                double[] min = null;\n                double[] max = null;\n\n                while (upstream.hasNext()) {\n                    UpstreamEntry<K, V> entity = upstream.next();\n                    LabeledVector row = basePreprocessor.apply(entity.getKey(), entity.getValue());\n\n                    if (min == null) {\n                        min = new double[row.size()];\n                        for (int i = 0; i < min.length; i++)\n                            min[i] = Double.MAX_VALUE;\n                    }\n                    else\n                        assert min.length == row.size() : \"Base preprocessor must return exactly \" + min.length\n                            + \" features\";\n\n                    if (max == null) {\n                        max = new double[row.size()];\n                        for (int i = 0; i < max.length; i++)\n                            max[i] = -Double.MAX_VALUE;\n                    }\n                    else\n                        assert max.length == row.size() : \"Base preprocessor must return exactly \" + min.length\n                            + \" features\";\n\n                    for (int i = 0; i < row.size(); i++) {\n                        if (row.get(i) < min[i])\n                            min[i] = row.get(i);\n                        if (row.get(i) > max[i])\n                            max[i] = row.get(i);\n                    }\n                }\n\n                return new MinMaxScalerPartitionData(min, max);\n            }, learningEnvironment(basePreprocessor)\n        )) {\n            double[][] minMax = dataset.compute(\n                data -> data.getMin() != null ? new double[][]{ data.getMin(), data.getMax() } : null,\n                (a, b) -> {\n                    if (a == null)\n                        return b;\n\n                    if (b == null)\n                        return a;\n\n                    double[][] res = new double[2][];\n\n                    res[0] = new double[a[0].length];\n                    for (int i = 0; i < res[0].length; i++)\n                        res[0][i] = Math.min(a[0][i], b[0][i]);\n\n                    res[1] = new double[a[1].length];\n                    for (int i = 0; i < res[1].length; i++)\n                        res[1][i] = Math.max(a[1][i], b[1][i]);\n\n                    return res;\n                }\n            );\n\n            return new MinMaxScalerPreprocessor<>(minMax[0], minMax[1], basePreprocessor);\n        }\n        catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }", "signature": "MinMaxScalerPreprocessor<K, V> fit(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "full_signature": "@Override public MinMaxScalerPreprocessor<K, V> fit(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "class_method_signature": "MinMaxScalerTrainer.fit(\n        LearningEnvironmentBuilder envBuilder,\n        DatasetBuilder<K, V> datasetBuilder,\n        Preprocessor<K, V> basePreprocessor)", "testcase": false, "constructor": false, "invocations": ["build", "hasNext", "next", "apply", "getKey", "getValue", "size", "size", "size", "size", "size", "get", "get", "get", "get", "learningEnvironment", "compute", "getMin", "getMin", "getMax", "min", "max"]}, "repository": {"repo_id": 170496871, "url": "https://github.com/gridgain/gridgain", "stars": 46, "created": "2/13/2019 11:31:35 AM +00:00", "updates": "2020-01-27T16:02:24+00:00", "fork": "False", "license": "licensed"}}