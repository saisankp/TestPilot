{"test_class": {"identifier": "KafkaConfigBackingStoreTest", "superclass": "", "interfaces": "", "fields": [{"original_string": "private static final String TOPIC = \"connect-configs\";", "modifier": "private static final", "type": "String", "declarator": "TOPIC = \"connect-configs\"", "var_name": "TOPIC"}, {"original_string": "private static final Map<String, String> DEFAULT_CONFIG_STORAGE_PROPS = new HashMap<>();", "modifier": "private static final", "type": "Map<String, String>", "declarator": "DEFAULT_CONFIG_STORAGE_PROPS = new HashMap<>()", "var_name": "DEFAULT_CONFIG_STORAGE_PROPS"}, {"original_string": "private static final DistributedConfig DEFAULT_DISTRIBUTED_CONFIG;", "modifier": "private static final", "type": "DistributedConfig", "declarator": "DEFAULT_DISTRIBUTED_CONFIG", "var_name": "DEFAULT_DISTRIBUTED_CONFIG"}, {"original_string": "private static final List<String> CONNECTOR_IDS = Arrays.asList(\"connector1\", \"connector2\");", "modifier": "private static final", "type": "List<String>", "declarator": "CONNECTOR_IDS = Arrays.asList(\"connector1\", \"connector2\")", "var_name": "CONNECTOR_IDS"}, {"original_string": "private static final List<String> CONNECTOR_CONFIG_KEYS = Arrays.asList(\"connector-connector1\", \"connector-connector2\");", "modifier": "private static final", "type": "List<String>", "declarator": "CONNECTOR_CONFIG_KEYS = Arrays.asList(\"connector-connector1\", \"connector-connector2\")", "var_name": "CONNECTOR_CONFIG_KEYS"}, {"original_string": "private static final List<String> COMMIT_TASKS_CONFIG_KEYS = Arrays.asList(\"commit-connector1\", \"commit-connector2\");", "modifier": "private static final", "type": "List<String>", "declarator": "COMMIT_TASKS_CONFIG_KEYS = Arrays.asList(\"commit-connector1\", \"commit-connector2\")", "var_name": "COMMIT_TASKS_CONFIG_KEYS"}, {"original_string": "private static final List<String> TARGET_STATE_KEYS =  Arrays.asList(\"target-state-connector1\", \"target-state-connector2\");", "modifier": "private static final", "type": "List<String>", "declarator": "TARGET_STATE_KEYS =  Arrays.asList(\"target-state-connector1\", \"target-state-connector2\")", "var_name": "TARGET_STATE_KEYS"}, {"original_string": "private static final List<ConnectorTaskId> TASK_IDS = Arrays.asList(\n            new ConnectorTaskId(\"connector1\", 0),\n            new ConnectorTaskId(\"connector1\", 1),\n            new ConnectorTaskId(\"connector2\", 0)\n    );", "modifier": "private static final", "type": "List<ConnectorTaskId>", "declarator": "TASK_IDS = Arrays.asList(\n            new ConnectorTaskId(\"connector1\", 0),\n            new ConnectorTaskId(\"connector1\", 1),\n            new ConnectorTaskId(\"connector2\", 0)\n    )", "var_name": "TASK_IDS"}, {"original_string": "private static final List<String> TASK_CONFIG_KEYS = Arrays.asList(\"task-connector1-0\", \"task-connector1-1\", \"task-connector2-0\");", "modifier": "private static final", "type": "List<String>", "declarator": "TASK_CONFIG_KEYS = Arrays.asList(\"task-connector1-0\", \"task-connector1-1\", \"task-connector2-0\")", "var_name": "TASK_CONFIG_KEYS"}, {"original_string": "private static final List<Map<String, String>> SAMPLE_CONFIGS = Arrays.asList(\n            Collections.singletonMap(\"config-key-one\", \"config-value-one\"),\n            Collections.singletonMap(\"config-key-two\", \"config-value-two\"),\n            Collections.singletonMap(\"config-key-three\", \"config-value-three\")\n    );", "modifier": "private static final", "type": "List<Map<String, String>>", "declarator": "SAMPLE_CONFIGS = Arrays.asList(\n            Collections.singletonMap(\"config-key-one\", \"config-value-one\"),\n            Collections.singletonMap(\"config-key-two\", \"config-value-two\"),\n            Collections.singletonMap(\"config-key-three\", \"config-value-three\")\n    )", "var_name": "SAMPLE_CONFIGS"}, {"original_string": "private static final List<Struct> CONNECTOR_CONFIG_STRUCTS = Arrays.asList(\n            new Struct(KafkaConfigBackingStore.CONNECTOR_CONFIGURATION_V0).put(\"properties\", SAMPLE_CONFIGS.get(0)),\n            new Struct(KafkaConfigBackingStore.CONNECTOR_CONFIGURATION_V0).put(\"properties\", SAMPLE_CONFIGS.get(1)),\n            new Struct(KafkaConfigBackingStore.CONNECTOR_CONFIGURATION_V0).put(\"properties\", SAMPLE_CONFIGS.get(2))\n    );", "modifier": "private static final", "type": "List<Struct>", "declarator": "CONNECTOR_CONFIG_STRUCTS = Arrays.asList(\n            new Struct(KafkaConfigBackingStore.CONNECTOR_CONFIGURATION_V0).put(\"properties\", SAMPLE_CONFIGS.get(0)),\n            new Struct(KafkaConfigBackingStore.CONNECTOR_CONFIGURATION_V0).put(\"properties\", SAMPLE_CONFIGS.get(1)),\n            new Struct(KafkaConfigBackingStore.CONNECTOR_CONFIGURATION_V0).put(\"properties\", SAMPLE_CONFIGS.get(2))\n    )", "var_name": "CONNECTOR_CONFIG_STRUCTS"}, {"original_string": "private static final List<Struct> TASK_CONFIG_STRUCTS = Arrays.asList(\n            new Struct(KafkaConfigBackingStore.TASK_CONFIGURATION_V0).put(\"properties\", SAMPLE_CONFIGS.get(0)),\n            new Struct(KafkaConfigBackingStore.TASK_CONFIGURATION_V0).put(\"properties\", SAMPLE_CONFIGS.get(1))\n    );", "modifier": "private static final", "type": "List<Struct>", "declarator": "TASK_CONFIG_STRUCTS = Arrays.asList(\n            new Struct(KafkaConfigBackingStore.TASK_CONFIGURATION_V0).put(\"properties\", SAMPLE_CONFIGS.get(0)),\n            new Struct(KafkaConfigBackingStore.TASK_CONFIGURATION_V0).put(\"properties\", SAMPLE_CONFIGS.get(1))\n    )", "var_name": "TASK_CONFIG_STRUCTS"}, {"original_string": "private static final Struct TARGET_STATE_PAUSED = new Struct(KafkaConfigBackingStore.TARGET_STATE_V0).put(\"state\", \"PAUSED\");", "modifier": "private static final", "type": "Struct", "declarator": "TARGET_STATE_PAUSED = new Struct(KafkaConfigBackingStore.TARGET_STATE_V0).put(\"state\", \"PAUSED\")", "var_name": "TARGET_STATE_PAUSED"}, {"original_string": "private static final Struct TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR\n            = new Struct(KafkaConfigBackingStore.CONNECTOR_TASKS_COMMIT_V0).put(\"tasks\", 2);", "modifier": "private static final", "type": "Struct", "declarator": "TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR\n            = new Struct(KafkaConfigBackingStore.CONNECTOR_TASKS_COMMIT_V0).put(\"tasks\", 2)", "var_name": "TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR"}, {"original_string": "private static final Struct TASKS_COMMIT_STRUCT_ZERO_TASK_CONNECTOR\n            = new Struct(KafkaConfigBackingStore.CONNECTOR_TASKS_COMMIT_V0).put(\"tasks\", 0);", "modifier": "private static final", "type": "Struct", "declarator": "TASKS_COMMIT_STRUCT_ZERO_TASK_CONNECTOR\n            = new Struct(KafkaConfigBackingStore.CONNECTOR_TASKS_COMMIT_V0).put(\"tasks\", 0)", "var_name": "TASKS_COMMIT_STRUCT_ZERO_TASK_CONNECTOR"}, {"original_string": "private static final List<byte[]> CONFIGS_SERIALIZED = Arrays.asList(\n            \"config-bytes-1\".getBytes(), \"config-bytes-2\".getBytes(), \"config-bytes-3\".getBytes(),\n            \"config-bytes-4\".getBytes(), \"config-bytes-5\".getBytes(), \"config-bytes-6\".getBytes(),\n            \"config-bytes-7\".getBytes(), \"config-bytes-8\".getBytes(), \"config-bytes-9\".getBytes()\n    );", "modifier": "private static final", "type": "List<byte[]>", "declarator": "CONFIGS_SERIALIZED = Arrays.asList(\n            \"config-bytes-1\".getBytes(), \"config-bytes-2\".getBytes(), \"config-bytes-3\".getBytes(),\n            \"config-bytes-4\".getBytes(), \"config-bytes-5\".getBytes(), \"config-bytes-6\".getBytes(),\n            \"config-bytes-7\".getBytes(), \"config-bytes-8\".getBytes(), \"config-bytes-9\".getBytes()\n    )", "var_name": "CONFIGS_SERIALIZED"}, {"original_string": "@Mock\n    private Converter converter;", "modifier": "@Mock\n    private", "type": "Converter", "declarator": "converter", "var_name": "converter"}, {"original_string": "@Mock\n    private ConfigBackingStore.UpdateListener configUpdateListener;", "modifier": "@Mock\n    private", "type": "ConfigBackingStore.UpdateListener", "declarator": "configUpdateListener", "var_name": "configUpdateListener"}, {"original_string": "@Mock\n    KafkaBasedLog<String, byte[]> storeLog;", "modifier": "@Mock", "type": "KafkaBasedLog<String, byte[]>", "declarator": "storeLog", "var_name": "storeLog"}, {"original_string": "private KafkaConfigBackingStore configStorage;", "modifier": "private", "type": "KafkaConfigBackingStore", "declarator": "configStorage", "var_name": "configStorage"}, {"original_string": "private Capture<String> capturedTopic = EasyMock.newCapture();", "modifier": "private", "type": "Capture<String>", "declarator": "capturedTopic = EasyMock.newCapture()", "var_name": "capturedTopic"}, {"original_string": "private Capture<Map<String, Object>> capturedProducerProps = EasyMock.newCapture();", "modifier": "private", "type": "Capture<Map<String, Object>>", "declarator": "capturedProducerProps = EasyMock.newCapture()", "var_name": "capturedProducerProps"}, {"original_string": "private Capture<Map<String, Object>> capturedConsumerProps = EasyMock.newCapture();", "modifier": "private", "type": "Capture<Map<String, Object>>", "declarator": "capturedConsumerProps = EasyMock.newCapture()", "var_name": "capturedConsumerProps"}, {"original_string": "private Capture<Callback<ConsumerRecord<String, byte[]>>> capturedConsumedCallback = EasyMock.newCapture();", "modifier": "private", "type": "Capture<Callback<ConsumerRecord<String, byte[]>>>", "declarator": "capturedConsumedCallback = EasyMock.newCapture()", "var_name": "capturedConsumedCallback"}, {"original_string": "private long logOffset = 0;", "modifier": "private", "type": "long", "declarator": "logOffset = 0", "var_name": "logOffset"}], "file": "connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java"}, "test_case": {"identifier": "testPutTaskConfigs", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n    public void testPutTaskConfigs() throws Exception {\n        expectConfigure();\n        expectStart(Collections.EMPTY_LIST, Collections.EMPTY_MAP);\n\n        // Task configs should read to end, write to the log, read to end, write root, then read to end again\n        expectReadToEnd(new LinkedHashMap<String, byte[]>());\n        expectConvertWriteRead(\n                TASK_CONFIG_KEYS.get(0), KafkaConfigBackingStore.TASK_CONFIGURATION_V0, CONFIGS_SERIALIZED.get(0),\n                \"properties\", SAMPLE_CONFIGS.get(0));\n        expectConvertWriteRead(\n                TASK_CONFIG_KEYS.get(1), KafkaConfigBackingStore.TASK_CONFIGURATION_V0, CONFIGS_SERIALIZED.get(1),\n                \"properties\", SAMPLE_CONFIGS.get(1));\n        expectReadToEnd(new LinkedHashMap<String, byte[]>());\n        expectConvertWriteRead(\n                COMMIT_TASKS_CONFIG_KEYS.get(0), KafkaConfigBackingStore.CONNECTOR_TASKS_COMMIT_V0, CONFIGS_SERIALIZED.get(2),\n                \"tasks\", 2); // Starts with 0 tasks, after update has 2\n        // As soon as root is rewritten, we should see a callback notifying us that we reconfigured some tasks\n        configUpdateListener.onTaskConfigUpdate(Arrays.asList(TASK_IDS.get(0), TASK_IDS.get(1)));\n        EasyMock.expectLastCall();\n\n        // Records to be read by consumer as it reads to the end of the log\n        LinkedHashMap<String, byte[]> serializedConfigs = new LinkedHashMap<>();\n        serializedConfigs.put(TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0));\n        serializedConfigs.put(TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(1));\n        serializedConfigs.put(COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(2));\n        expectReadToEnd(serializedConfigs);\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n\n        configStorage.configure(DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        // Bootstrap as if we had already added the connector, but no tasks had been added yet\n        whiteboxAddConnector(CONNECTOR_IDS.get(0), SAMPLE_CONFIGS.get(0), Collections.EMPTY_LIST);\n\n        // Null before writing\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(-1, configState.offset());\n        assertNull(configState.taskConfig(TASK_IDS.get(0)));\n        assertNull(configState.taskConfig(TASK_IDS.get(1)));\n\n        // Writing task task configs should block until all the writes have been performed and the root record update\n        // has completed\n        List<Map<String, String>> taskConfigs = Arrays.asList(SAMPLE_CONFIGS.get(0), SAMPLE_CONFIGS.get(1));\n        configStorage.putTaskConfigs(\"connector1\", taskConfigs);\n\n        // Validate root config by listing all connectors and tasks\n        configState = configStorage.snapshot();\n        assertEquals(3, configState.offset());\n        String connectorName = CONNECTOR_IDS.get(0);\n        assertEquals(Arrays.asList(connectorName), new ArrayList<>(configState.connectors()));\n        assertEquals(Arrays.asList(TASK_IDS.get(0), TASK_IDS.get(1)), configState.tasks(connectorName));\n        assertEquals(SAMPLE_CONFIGS.get(0), configState.taskConfig(TASK_IDS.get(0)));\n        assertEquals(SAMPLE_CONFIGS.get(1), configState.taskConfig(TASK_IDS.get(1)));\n        assertEquals(Collections.EMPTY_SET, configState.inconsistentConnectors());\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }", "signature": "void testPutTaskConfigs()", "full_signature": "@Test public void testPutTaskConfigs()", "class_method_signature": "KafkaConfigBackingStoreTest.testPutTaskConfigs()", "testcase": true, "constructor": false, "invocations": ["expectConfigure", "expectStart", "expectReadToEnd", "expectConvertWriteRead", "get", "get", "get", "expectConvertWriteRead", "get", "get", "get", "expectReadToEnd", "expectConvertWriteRead", "get", "get", "onTaskConfigUpdate", "asList", "get", "get", "expectLastCall", "put", "get", "get", "put", "get", "get", "put", "get", "get", "expectReadToEnd", "expectStop", "replayAll", "configure", "start", "whiteboxAddConnector", "get", "get", "snapshot", "assertEquals", "offset", "assertNull", "taskConfig", "get", "assertNull", "taskConfig", "get", "asList", "get", "get", "putTaskConfigs", "snapshot", "assertEquals", "offset", "get", "assertEquals", "asList", "connectors", "assertEquals", "asList", "get", "get", "tasks", "assertEquals", "get", "taskConfig", "get", "assertEquals", "get", "taskConfig", "get", "assertEquals", "inconsistentConnectors", "stop", "verifyAll"]}, "focal_class": {"identifier": "KafkaConfigBackingStore", "superclass": "", "interfaces": "implements ConfigBackingStore", "fields": [{"original_string": "private static final Logger log = LoggerFactory.getLogger(KafkaConfigBackingStore.class);", "modifier": "private static final", "type": "Logger", "declarator": "log = LoggerFactory.getLogger(KafkaConfigBackingStore.class)", "var_name": "log"}, {"original_string": "public static final String TARGET_STATE_PREFIX = \"target-state-\";", "modifier": "public static final", "type": "String", "declarator": "TARGET_STATE_PREFIX = \"target-state-\"", "var_name": "TARGET_STATE_PREFIX"}, {"original_string": "public static final String CONNECTOR_PREFIX = \"connector-\";", "modifier": "public static final", "type": "String", "declarator": "CONNECTOR_PREFIX = \"connector-\"", "var_name": "CONNECTOR_PREFIX"}, {"original_string": "public static final String TASK_PREFIX = \"task-\";", "modifier": "public static final", "type": "String", "declarator": "TASK_PREFIX = \"task-\"", "var_name": "TASK_PREFIX"}, {"original_string": "public static final String COMMIT_TASKS_PREFIX = \"commit-\";", "modifier": "public static final", "type": "String", "declarator": "COMMIT_TASKS_PREFIX = \"commit-\"", "var_name": "COMMIT_TASKS_PREFIX"}, {"original_string": "public static final Schema CONNECTOR_CONFIGURATION_V0 = SchemaBuilder.struct()\n            .field(\"properties\", SchemaBuilder.map(Schema.STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA).build())\n            .build();", "modifier": "public static final", "type": "Schema", "declarator": "CONNECTOR_CONFIGURATION_V0 = SchemaBuilder.struct()\n            .field(\"properties\", SchemaBuilder.map(Schema.STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA).build())\n            .build()", "var_name": "CONNECTOR_CONFIGURATION_V0"}, {"original_string": "public static final Schema TASK_CONFIGURATION_V0 = CONNECTOR_CONFIGURATION_V0;", "modifier": "public static final", "type": "Schema", "declarator": "TASK_CONFIGURATION_V0 = CONNECTOR_CONFIGURATION_V0", "var_name": "TASK_CONFIGURATION_V0"}, {"original_string": "public static final Schema CONNECTOR_TASKS_COMMIT_V0 = SchemaBuilder.struct()\n            .field(\"tasks\", Schema.INT32_SCHEMA)\n            .build();", "modifier": "public static final", "type": "Schema", "declarator": "CONNECTOR_TASKS_COMMIT_V0 = SchemaBuilder.struct()\n            .field(\"tasks\", Schema.INT32_SCHEMA)\n            .build()", "var_name": "CONNECTOR_TASKS_COMMIT_V0"}, {"original_string": "public static final Schema TARGET_STATE_V0 = SchemaBuilder.struct()\n            .field(\"state\", Schema.STRING_SCHEMA)\n            .build();", "modifier": "public static final", "type": "Schema", "declarator": "TARGET_STATE_V0 = SchemaBuilder.struct()\n            .field(\"state\", Schema.STRING_SCHEMA)\n            .build()", "var_name": "TARGET_STATE_V0"}, {"original_string": "private static final long READ_TO_END_TIMEOUT_MS = 30000;", "modifier": "private static final", "type": "long", "declarator": "READ_TO_END_TIMEOUT_MS = 30000", "var_name": "READ_TO_END_TIMEOUT_MS"}, {"original_string": "private final Object lock;", "modifier": "private final", "type": "Object", "declarator": "lock", "var_name": "lock"}, {"original_string": "private boolean starting;", "modifier": "private", "type": "boolean", "declarator": "starting", "var_name": "starting"}, {"original_string": "private final Converter converter;", "modifier": "private final", "type": "Converter", "declarator": "converter", "var_name": "converter"}, {"original_string": "private UpdateListener updateListener;", "modifier": "private", "type": "UpdateListener", "declarator": "updateListener", "var_name": "updateListener"}, {"original_string": "private String topic;", "modifier": "private", "type": "String", "declarator": "topic", "var_name": "topic"}, {"original_string": "private KafkaBasedLog<String, byte[]> configLog;", "modifier": "private", "type": "KafkaBasedLog<String, byte[]>", "declarator": "configLog", "var_name": "configLog"}, {"original_string": "private Map<String, Integer> connectorTaskCounts = new HashMap<>();", "modifier": "private", "type": "Map<String, Integer>", "declarator": "connectorTaskCounts = new HashMap<>()", "var_name": "connectorTaskCounts"}, {"original_string": "private Map<String, Map<String, String>> connectorConfigs = new HashMap<>();", "modifier": "private", "type": "Map<String, Map<String, String>>", "declarator": "connectorConfigs = new HashMap<>()", "var_name": "connectorConfigs"}, {"original_string": "private Map<ConnectorTaskId, Map<String, String>> taskConfigs = new HashMap<>();", "modifier": "private", "type": "Map<ConnectorTaskId, Map<String, String>>", "declarator": "taskConfigs = new HashMap<>()", "var_name": "taskConfigs"}, {"original_string": "private Set<String> inconsistent = new HashSet<>();", "modifier": "private", "type": "Set<String>", "declarator": "inconsistent = new HashSet<>()", "var_name": "inconsistent"}, {"original_string": "private volatile long offset;", "modifier": "private volatile", "type": "long", "declarator": "offset", "var_name": "offset"}, {"original_string": "private final Map<String, Map<ConnectorTaskId, Map<String, String>>> deferredTaskUpdates = new HashMap<>();", "modifier": "private final", "type": "Map<String, Map<ConnectorTaskId, Map<String, String>>>", "declarator": "deferredTaskUpdates = new HashMap<>()", "var_name": "deferredTaskUpdates"}, {"original_string": "private final Map<String, TargetState> connectorTargetStates = new HashMap<>();", "modifier": "private final", "type": "Map<String, TargetState>", "declarator": "connectorTargetStates = new HashMap<>()", "var_name": "connectorTargetStates"}], "methods": [{"identifier": "TARGET_STATE_KEY", "parameters": "(String connectorName)", "modifiers": "public static", "return": "String", "signature": "String TARGET_STATE_KEY(String connectorName)", "full_signature": "public static String TARGET_STATE_KEY(String connectorName)", "class_method_signature": "KafkaConfigBackingStore.TARGET_STATE_KEY(String connectorName)", "testcase": false, "constructor": false}, {"identifier": "CONNECTOR_KEY", "parameters": "(String connectorName)", "modifiers": "public static", "return": "String", "signature": "String CONNECTOR_KEY(String connectorName)", "full_signature": "public static String CONNECTOR_KEY(String connectorName)", "class_method_signature": "KafkaConfigBackingStore.CONNECTOR_KEY(String connectorName)", "testcase": false, "constructor": false}, {"identifier": "TASK_KEY", "parameters": "(ConnectorTaskId taskId)", "modifiers": "public static", "return": "String", "signature": "String TASK_KEY(ConnectorTaskId taskId)", "full_signature": "public static String TASK_KEY(ConnectorTaskId taskId)", "class_method_signature": "KafkaConfigBackingStore.TASK_KEY(ConnectorTaskId taskId)", "testcase": false, "constructor": false}, {"identifier": "COMMIT_TASKS_KEY", "parameters": "(String connectorName)", "modifiers": "public static", "return": "String", "signature": "String COMMIT_TASKS_KEY(String connectorName)", "full_signature": "public static String COMMIT_TASKS_KEY(String connectorName)", "class_method_signature": "KafkaConfigBackingStore.COMMIT_TASKS_KEY(String connectorName)", "testcase": false, "constructor": false}, {"identifier": "KafkaConfigBackingStore", "parameters": "(Converter converter)", "modifiers": "public", "return": "", "signature": " KafkaConfigBackingStore(Converter converter)", "full_signature": "public  KafkaConfigBackingStore(Converter converter)", "class_method_signature": "KafkaConfigBackingStore.KafkaConfigBackingStore(Converter converter)", "testcase": false, "constructor": true}, {"identifier": "setUpdateListener", "parameters": "(UpdateListener listener)", "modifiers": "@Override public", "return": "void", "signature": "void setUpdateListener(UpdateListener listener)", "full_signature": "@Override public void setUpdateListener(UpdateListener listener)", "class_method_signature": "KafkaConfigBackingStore.setUpdateListener(UpdateListener listener)", "testcase": false, "constructor": false}, {"identifier": "configure", "parameters": "(WorkerConfig config)", "modifiers": "@Override public", "return": "void", "signature": "void configure(WorkerConfig config)", "full_signature": "@Override public void configure(WorkerConfig config)", "class_method_signature": "KafkaConfigBackingStore.configure(WorkerConfig config)", "testcase": false, "constructor": false}, {"identifier": "start", "parameters": "()", "modifiers": "@Override public", "return": "void", "signature": "void start()", "full_signature": "@Override public void start()", "class_method_signature": "KafkaConfigBackingStore.start()", "testcase": false, "constructor": false}, {"identifier": "stop", "parameters": "()", "modifiers": "@Override public", "return": "void", "signature": "void stop()", "full_signature": "@Override public void stop()", "class_method_signature": "KafkaConfigBackingStore.stop()", "testcase": false, "constructor": false}, {"identifier": "snapshot", "parameters": "()", "modifiers": "@Override public", "return": "ClusterConfigState", "signature": "ClusterConfigState snapshot()", "full_signature": "@Override public ClusterConfigState snapshot()", "class_method_signature": "KafkaConfigBackingStore.snapshot()", "testcase": false, "constructor": false}, {"identifier": "contains", "parameters": "(String connector)", "modifiers": "@Override public", "return": "boolean", "signature": "boolean contains(String connector)", "full_signature": "@Override public boolean contains(String connector)", "class_method_signature": "KafkaConfigBackingStore.contains(String connector)", "testcase": false, "constructor": false}, {"identifier": "putConnectorConfig", "parameters": "(String connector, Map<String, String> properties)", "modifiers": "@Override public", "return": "void", "signature": "void putConnectorConfig(String connector, Map<String, String> properties)", "full_signature": "@Override public void putConnectorConfig(String connector, Map<String, String> properties)", "class_method_signature": "KafkaConfigBackingStore.putConnectorConfig(String connector, Map<String, String> properties)", "testcase": false, "constructor": false}, {"identifier": "removeConnectorConfig", "parameters": "(String connector)", "modifiers": "@Override public", "return": "void", "signature": "void removeConnectorConfig(String connector)", "full_signature": "@Override public void removeConnectorConfig(String connector)", "class_method_signature": "KafkaConfigBackingStore.removeConnectorConfig(String connector)", "testcase": false, "constructor": false}, {"identifier": "removeTaskConfigs", "parameters": "(String connector)", "modifiers": "@Override public", "return": "void", "signature": "void removeTaskConfigs(String connector)", "full_signature": "@Override public void removeTaskConfigs(String connector)", "class_method_signature": "KafkaConfigBackingStore.removeTaskConfigs(String connector)", "testcase": false, "constructor": false}, {"identifier": "updateConnectorConfig", "parameters": "(String connector, byte[] serializedConfig)", "modifiers": "private", "return": "void", "signature": "void updateConnectorConfig(String connector, byte[] serializedConfig)", "full_signature": "private void updateConnectorConfig(String connector, byte[] serializedConfig)", "class_method_signature": "KafkaConfigBackingStore.updateConnectorConfig(String connector, byte[] serializedConfig)", "testcase": false, "constructor": false}, {"identifier": "putTaskConfigs", "parameters": "(String connector, List<Map<String, String>> configs)", "modifiers": "@Override public", "return": "void", "signature": "void putTaskConfigs(String connector, List<Map<String, String>> configs)", "full_signature": "@Override public void putTaskConfigs(String connector, List<Map<String, String>> configs)", "class_method_signature": "KafkaConfigBackingStore.putTaskConfigs(String connector, List<Map<String, String>> configs)", "testcase": false, "constructor": false}, {"identifier": "refresh", "parameters": "(long timeout, TimeUnit unit)", "modifiers": "@Override public", "return": "void", "signature": "void refresh(long timeout, TimeUnit unit)", "full_signature": "@Override public void refresh(long timeout, TimeUnit unit)", "class_method_signature": "KafkaConfigBackingStore.refresh(long timeout, TimeUnit unit)", "testcase": false, "constructor": false}, {"identifier": "putTargetState", "parameters": "(String connector, TargetState state)", "modifiers": "@Override public", "return": "void", "signature": "void putTargetState(String connector, TargetState state)", "full_signature": "@Override public void putTargetState(String connector, TargetState state)", "class_method_signature": "KafkaConfigBackingStore.putTargetState(String connector, TargetState state)", "testcase": false, "constructor": false}, {"identifier": "createKafkaBasedLog", "parameters": "(String topic, Map<String, Object> producerProps,\n                                                              Map<String, Object> consumerProps, Callback<ConsumerRecord<String, byte[]>> consumedCallback)", "modifiers": "private", "return": "KafkaBasedLog<String, byte[]>", "signature": "KafkaBasedLog<String, byte[]> createKafkaBasedLog(String topic, Map<String, Object> producerProps,\n                                                              Map<String, Object> consumerProps, Callback<ConsumerRecord<String, byte[]>> consumedCallback)", "full_signature": "private KafkaBasedLog<String, byte[]> createKafkaBasedLog(String topic, Map<String, Object> producerProps,\n                                                              Map<String, Object> consumerProps, Callback<ConsumerRecord<String, byte[]>> consumedCallback)", "class_method_signature": "KafkaConfigBackingStore.createKafkaBasedLog(String topic, Map<String, Object> producerProps,\n                                                              Map<String, Object> consumerProps, Callback<ConsumerRecord<String, byte[]>> consumedCallback)", "testcase": false, "constructor": false}, {"identifier": "parseTaskId", "parameters": "(String key)", "modifiers": "private", "return": "ConnectorTaskId", "signature": "ConnectorTaskId parseTaskId(String key)", "full_signature": "private ConnectorTaskId parseTaskId(String key)", "class_method_signature": "KafkaConfigBackingStore.parseTaskId(String key)", "testcase": false, "constructor": false}, {"identifier": "taskIds", "parameters": "(String connector, Map<ConnectorTaskId, Map<String, String>> configs)", "modifiers": "private", "return": "Set<Integer>", "signature": "Set<Integer> taskIds(String connector, Map<ConnectorTaskId, Map<String, String>> configs)", "full_signature": "private Set<Integer> taskIds(String connector, Map<ConnectorTaskId, Map<String, String>> configs)", "class_method_signature": "KafkaConfigBackingStore.taskIds(String connector, Map<ConnectorTaskId, Map<String, String>> configs)", "testcase": false, "constructor": false}, {"identifier": "completeTaskIdSet", "parameters": "(Set<Integer> idSet, int expectedSize)", "modifiers": "private", "return": "boolean", "signature": "boolean completeTaskIdSet(Set<Integer> idSet, int expectedSize)", "full_signature": "private boolean completeTaskIdSet(Set<Integer> idSet, int expectedSize)", "class_method_signature": "KafkaConfigBackingStore.completeTaskIdSet(Set<Integer> idSet, int expectedSize)", "testcase": false, "constructor": false}, {"identifier": "intValue", "parameters": "(Object value)", "modifiers": "private static", "return": "int", "signature": "int intValue(Object value)", "full_signature": "private static int intValue(Object value)", "class_method_signature": "KafkaConfigBackingStore.intValue(Object value)", "testcase": false, "constructor": false}], "file": "connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaConfigBackingStore.java"}, "focal_method": {"identifier": "putTaskConfigs", "parameters": "(String connector, List<Map<String, String>> configs)", "modifiers": "@Override public", "return": "void", "body": "@Override\n    public void putTaskConfigs(String connector, List<Map<String, String>> configs) {\n        // Make sure we're at the end of the log. We should be the only writer, but we want to make sure we don't have\n        // any outstanding lagging data to consume.\n        try {\n            configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n            log.error(\"Failed to write root configuration to Kafka: \", e);\n            throw new ConnectException(\"Error writing root configuration to Kafka\", e);\n        }\n\n        int taskCount = configs.size();\n\n        // Start sending all the individual updates\n        int index = 0;\n        for (Map<String, String> taskConfig: configs) {\n            Struct connectConfig = new Struct(TASK_CONFIGURATION_V0);\n            connectConfig.put(\"properties\", taskConfig);\n            byte[] serializedConfig = converter.fromConnectData(topic, TASK_CONFIGURATION_V0, connectConfig);\n            log.debug(\"Writing configuration for task \" + index + \" configuration: \" + taskConfig);\n            ConnectorTaskId connectorTaskId = new ConnectorTaskId(connector, index);\n            configLog.send(TASK_KEY(connectorTaskId), serializedConfig);\n            index++;\n        }\n\n        // Finally, send the commit to update the number of tasks and apply the new configs, then wait until we read to\n        // the end of the log\n        try {\n            // Read to end to ensure all the task configs have been written\n            if (taskCount > 0) {\n                configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n            }\n            // Write the commit message\n            Struct connectConfig = new Struct(CONNECTOR_TASKS_COMMIT_V0);\n            connectConfig.put(\"tasks\", taskCount);\n            byte[] serializedConfig = converter.fromConnectData(topic, CONNECTOR_TASKS_COMMIT_V0, connectConfig);\n            log.debug(\"Writing commit for connector \" + connector + \" with \" + taskCount + \" tasks.\");\n            configLog.send(COMMIT_TASKS_KEY(connector), serializedConfig);\n\n            // Read to end to ensure all the commit messages have been written\n            configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n            log.error(\"Failed to write root configuration to Kafka: \", e);\n            throw new ConnectException(\"Error writing root configuration to Kafka\", e);\n        }\n    }", "signature": "void putTaskConfigs(String connector, List<Map<String, String>> configs)", "full_signature": "@Override public void putTaskConfigs(String connector, List<Map<String, String>> configs)", "class_method_signature": "KafkaConfigBackingStore.putTaskConfigs(String connector, List<Map<String, String>> configs)", "testcase": false, "constructor": false, "invocations": ["get", "readToEnd", "error", "size", "put", "fromConnectData", "debug", "send", "TASK_KEY", "get", "readToEnd", "put", "fromConnectData", "debug", "send", "COMMIT_TASKS_KEY", "get", "readToEnd", "error"]}, "repository": {"repo_id": 135978112, "url": "https://github.com/anurnomeru/kafka-0.10.0.1-source-reading", "language": "Java", "is_fork": false, "fork_count": 1, "stargazer_count": 7, "size": 2953, "license": "licensed"}}