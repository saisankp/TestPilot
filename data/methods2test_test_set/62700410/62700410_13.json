{"test_class": {"identifier": "CSVSparkTransformTest", "superclass": "", "interfaces": "", "fields": [], "file": "datavec-spark-inference-parent/datavec-spark-inference-model/src/test/java/org/datavec/spark/transform/CSVSparkTransformTest.java"}, "test_case": {"identifier": "testTransformerBatch", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n    public void testTransformerBatch() throws Exception {\n        List<Writable> input = new ArrayList<>();\n        input.add(new DoubleWritable(1.0));\n        input.add(new DoubleWritable(2.0));\n\n        Schema schema = new Schema.Builder().addColumnDouble(\"1.0\").addColumnDouble(\"2.0\").build();\n        List<Writable> output = new ArrayList<>();\n        output.add(new Text(\"1.0\"));\n        output.add(new Text(\"2.0\"));\n\n        TransformProcess transformProcess =\n                new TransformProcess.Builder(schema).convertToString(\"1.0\").convertToString(\"2.0\").build();\n        CSVSparkTransform csvSparkTransform = new CSVSparkTransform(transformProcess);\n        String[] values = new String[] {\"1.0\", \"2.0\"};\n        SingleCSVRecord record = csvSparkTransform.transform(new SingleCSVRecord(values));\n        BatchCSVRecord batchCSVRecord = new BatchCSVRecord();\n        for (int i = 0; i < 3; i++)\n            batchCSVRecord.add(record);\n        //data type is string, unable to convert\n        BatchCSVRecord batchCSVRecord1 = csvSparkTransform.transform(batchCSVRecord);\n      /*  Base64NDArrayBody body = csvSparkTransform.toArray(batchCSVRecord1);\n        INDArray fromBase64 = Nd4jBase64.fromBase64(body.getNdarray());\n        assertTrue(fromBase64.isMatrix());\n        System.out.println(\"Base 64ed array \" + fromBase64); */\n    }", "signature": "void testTransformerBatch()", "full_signature": "@Test public void testTransformerBatch()", "class_method_signature": "CSVSparkTransformTest.testTransformerBatch()", "testcase": true, "constructor": false, "invocations": ["add", "add", "build", "addColumnDouble", "addColumnDouble", "add", "add", "build", "convertToString", "convertToString", "transform", "add", "transform"]}, "focal_class": {"identifier": "CSVSparkTransform", "superclass": "", "interfaces": "", "fields": [{"original_string": "@Getter\n    private TransformProcess transformProcess;", "modifier": "@Getter\n    private", "type": "TransformProcess", "declarator": "transformProcess", "var_name": "transformProcess"}, {"original_string": "private static BufferAllocator bufferAllocator = new RootAllocator(Long.MAX_VALUE);", "modifier": "private static", "type": "BufferAllocator", "declarator": "bufferAllocator = new RootAllocator(Long.MAX_VALUE)", "var_name": "bufferAllocator"}], "methods": [{"identifier": "toArray", "parameters": "(BatchCSVRecord batch)", "modifiers": "public", "return": "Base64NDArrayBody", "signature": "Base64NDArrayBody toArray(BatchCSVRecord batch)", "full_signature": "public Base64NDArrayBody toArray(BatchCSVRecord batch)", "class_method_signature": "CSVSparkTransform.toArray(BatchCSVRecord batch)", "testcase": false, "constructor": false}, {"identifier": "toArray", "parameters": "(SingleCSVRecord record)", "modifiers": "public", "return": "Base64NDArrayBody", "signature": "Base64NDArrayBody toArray(SingleCSVRecord record)", "full_signature": "public Base64NDArrayBody toArray(SingleCSVRecord record)", "class_method_signature": "CSVSparkTransform.toArray(SingleCSVRecord record)", "testcase": false, "constructor": false}, {"identifier": "transform", "parameters": "(BatchCSVRecord batch)", "modifiers": "public", "return": "BatchCSVRecord", "signature": "BatchCSVRecord transform(BatchCSVRecord batch)", "full_signature": "public BatchCSVRecord transform(BatchCSVRecord batch)", "class_method_signature": "CSVSparkTransform.transform(BatchCSVRecord batch)", "testcase": false, "constructor": false}, {"identifier": "transform", "parameters": "(SingleCSVRecord record)", "modifiers": "public", "return": "SingleCSVRecord", "signature": "SingleCSVRecord transform(SingleCSVRecord record)", "full_signature": "public SingleCSVRecord transform(SingleCSVRecord record)", "class_method_signature": "CSVSparkTransform.transform(SingleCSVRecord record)", "testcase": false, "constructor": false}, {"identifier": "transformSequenceIncremental", "parameters": "(BatchCSVRecord transform)", "modifiers": "public", "return": "SequenceBatchCSVRecord", "signature": "SequenceBatchCSVRecord transformSequenceIncremental(BatchCSVRecord transform)", "full_signature": "public SequenceBatchCSVRecord transformSequenceIncremental(BatchCSVRecord transform)", "class_method_signature": "CSVSparkTransform.transformSequenceIncremental(BatchCSVRecord transform)", "testcase": false, "constructor": false}, {"identifier": "transformSequence", "parameters": "(SequenceBatchCSVRecord batchCSVRecordSequence)", "modifiers": "public", "return": "SequenceBatchCSVRecord", "signature": "SequenceBatchCSVRecord transformSequence(SequenceBatchCSVRecord batchCSVRecordSequence)", "full_signature": "public SequenceBatchCSVRecord transformSequence(SequenceBatchCSVRecord batchCSVRecordSequence)", "class_method_signature": "CSVSparkTransform.transformSequence(SequenceBatchCSVRecord batchCSVRecordSequence)", "testcase": false, "constructor": false}, {"identifier": "transformSequenceArray", "parameters": "(SequenceBatchCSVRecord batchCSVRecordSequence)", "modifiers": "public", "return": "Base64NDArrayBody", "signature": "Base64NDArrayBody transformSequenceArray(SequenceBatchCSVRecord batchCSVRecordSequence)", "full_signature": "public Base64NDArrayBody transformSequenceArray(SequenceBatchCSVRecord batchCSVRecordSequence)", "class_method_signature": "CSVSparkTransform.transformSequenceArray(SequenceBatchCSVRecord batchCSVRecordSequence)", "testcase": false, "constructor": false}, {"identifier": "transformSequenceArrayIncremental", "parameters": "(BatchCSVRecord singleCsvRecord)", "modifiers": "public", "return": "Base64NDArrayBody", "signature": "Base64NDArrayBody transformSequenceArrayIncremental(BatchCSVRecord singleCsvRecord)", "full_signature": "public Base64NDArrayBody transformSequenceArrayIncremental(BatchCSVRecord singleCsvRecord)", "class_method_signature": "CSVSparkTransform.transformSequenceArrayIncremental(BatchCSVRecord singleCsvRecord)", "testcase": false, "constructor": false}, {"identifier": "transform", "parameters": "(SequenceBatchCSVRecord batchCSVRecord)", "modifiers": "public", "return": "SequenceBatchCSVRecord", "signature": "SequenceBatchCSVRecord transform(SequenceBatchCSVRecord batchCSVRecord)", "full_signature": "public SequenceBatchCSVRecord transform(SequenceBatchCSVRecord batchCSVRecord)", "class_method_signature": "CSVSparkTransform.transform(SequenceBatchCSVRecord batchCSVRecord)", "testcase": false, "constructor": false}], "file": "datavec-spark-inference-parent/datavec-spark-inference-model/src/main/java/org/datavec/spark/transform/CSVSparkTransform.java"}, "focal_method": {"identifier": "transform", "parameters": "(BatchCSVRecord batch)", "modifiers": "public", "return": "BatchCSVRecord", "body": "public BatchCSVRecord transform(BatchCSVRecord batch) {\n        BatchCSVRecord batchCSVRecord = new BatchCSVRecord();\n        List<List<Writable>> converted =  execute(toArrowWritables(toArrowColumnsString(\n                bufferAllocator,transformProcess.getInitialSchema(),\n                batch.getRecordsAsString()),\n                transformProcess.getInitialSchema()),transformProcess);\n        int numCols = converted.get(0).size();\n        for (int row = 0; row < converted.size(); row++) {\n            String[] values = new String[numCols];\n            for (int i = 0; i < values.length; i++)\n                values[i] = converted.get(row).get(i).toString();\n            batchCSVRecord.add(new SingleCSVRecord(values));\n        }\n\n        return batchCSVRecord;\n\n    }", "signature": "BatchCSVRecord transform(BatchCSVRecord batch)", "full_signature": "public BatchCSVRecord transform(BatchCSVRecord batch)", "class_method_signature": "CSVSparkTransform.transform(BatchCSVRecord batch)", "testcase": false, "constructor": false, "invocations": ["execute", "toArrowWritables", "toArrowColumnsString", "getInitialSchema", "getRecordsAsString", "getInitialSchema", "size", "get", "size", "toString", "get", "get", "add"]}, "repository": {"repo_id": 62700410, "url": "https://github.com/deeplearning4j/DataVec", "language": "Java", "is_fork": false, "fork_count": 174, "stargazer_count": 260, "size": 39842, "license": "licensed"}}