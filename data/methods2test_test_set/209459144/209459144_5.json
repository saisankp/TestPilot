{"test_class": {"identifier": "SparkSqlInterpreterTest", "superclass": "", "interfaces": "", "fields": [{"original_string": "private static SparkSqlInterpreter sqlInterpreter;", "modifier": "private static", "type": "SparkSqlInterpreter", "declarator": "sqlInterpreter", "var_name": "sqlInterpreter"}, {"original_string": "private static SparkInterpreter sparkInterpreter;", "modifier": "private static", "type": "SparkInterpreter", "declarator": "sparkInterpreter", "var_name": "sparkInterpreter"}], "file": "submarine-workbench/interpreter/spark-interpreter/src/test/java/org/apache/submarine/interpreter/SparkSqlInterpreterTest.java"}, "test_case": {"identifier": "testMaxResults", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n  public void testMaxResults() throws InterpreterException {\n    sparkInterpreter.interpret(\"case class P(age:Int)\");\n    sparkInterpreter.interpret(\n            \"val gr = sc.parallelize(Seq(P(1),P(2),P(3),P(4),P(5),P(6),P(7),P(8),P(9),P(10),P(11)))\");\n    sparkInterpreter.interpret(\"gr.toDF.registerTempTable(\\\"gr\\\")\");\n\n    InterpreterResult ret = sqlInterpreter.interpret(\"select * from gr\");\n    assertEquals(InterpreterResult.Code.SUCCESS, ret.code());\n    // the number of rows is 10+1, 1 is the head of table\n    assertEquals(11, ret.message().get(0).getData().split(\"\\n\").length);\n    assertTrue(ret.message().get(1).getData().contains(\"alert-warning\"));\n\n    // test limit local property\n    sqlInterpreter.setResultLimits(5);\n    ret = sqlInterpreter.interpret(\"select * from gr\");\n    assertEquals(InterpreterResult.Code.SUCCESS, ret.code());\n    // the number of rows is 5+1, 1 is the head of table\n    assertEquals(6, ret.message().get(0).getData().split(\"\\n\").length);\n  }", "signature": "void testMaxResults()", "full_signature": "@Test public void testMaxResults()", "class_method_signature": "SparkSqlInterpreterTest.testMaxResults()", "testcase": true, "constructor": false, "invocations": ["interpret", "interpret", "interpret", "interpret", "assertEquals", "code", "assertEquals", "split", "getData", "get", "message", "assertTrue", "contains", "getData", "get", "message", "setResultLimits", "interpret", "assertEquals", "code", "assertEquals", "split", "getData", "get", "message"]}, "focal_class": {"identifier": "SparkSqlInterpreter", "superclass": "extends AbstractInterpreter", "interfaces": "", "fields": [{"original_string": "private static final Logger LOG = LoggerFactory.getLogger(SparkInterpreter.class);", "modifier": "private static final", "type": "Logger", "declarator": "LOG = LoggerFactory.getLogger(SparkInterpreter.class)", "var_name": "LOG"}], "methods": [{"identifier": "SparkSqlInterpreter", "parameters": "(Properties properties)", "modifiers": "public", "return": "", "signature": " SparkSqlInterpreter(Properties properties)", "full_signature": "public  SparkSqlInterpreter(Properties properties)", "class_method_signature": "SparkSqlInterpreter.SparkSqlInterpreter(Properties properties)", "testcase": false, "constructor": true}, {"identifier": "SparkSqlInterpreter", "parameters": "()", "modifiers": "public", "return": "", "signature": " SparkSqlInterpreter()", "full_signature": "public  SparkSqlInterpreter()", "class_method_signature": "SparkSqlInterpreter.SparkSqlInterpreter()", "testcase": false, "constructor": true}, {"identifier": "test", "parameters": "()", "modifiers": "@Override public", "return": "boolean", "signature": "boolean test()", "full_signature": "@Override public boolean test()", "class_method_signature": "SparkSqlInterpreter.test()", "testcase": false, "constructor": false}, {"identifier": "setResultLimits", "parameters": "(long number)", "modifiers": "public", "return": "void", "signature": "void setResultLimits(long number)", "full_signature": "public void setResultLimits(long number)", "class_method_signature": "SparkSqlInterpreter.setResultLimits(long number)", "testcase": false, "constructor": false}], "file": "submarine-workbench/interpreter/spark-interpreter/src/main/java/org/apache/submarine/interpreter/SparkSqlInterpreter.java"}, "focal_method": {"identifier": "setResultLimits", "parameters": "(long number)", "modifiers": "public", "return": "void", "body": "public void setResultLimits(long number){\n    getIntpContext().getLocalProperties().put(\"limit\", String.valueOf(number));\n  }", "signature": "void setResultLimits(long number)", "full_signature": "public void setResultLimits(long number)", "class_method_signature": "SparkSqlInterpreter.setResultLimits(long number)", "testcase": false, "constructor": false, "invocations": ["put", "getLocalProperties", "getIntpContext", "valueOf"]}, "repository": {"repo_id": 209459144, "url": "https://github.com/apache/submarine", "stars": 185, "created": "9/19/2019 4:00:17 AM +00:00", "updates": "2020-01-27T15:27:05+00:00", "fork": "False", "license": "licensed"}}