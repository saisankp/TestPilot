{"test_class": {"identifier": "KafkaWriterTest", "superclass": "", "interfaces": "", "fields": [{"original_string": "private KafkaWriter processor;", "modifier": "private", "type": "KafkaWriter", "declarator": "processor", "var_name": "processor"}, {"original_string": "private kafka.javaapi.producer.Producer<String, String> producer;", "modifier": "private", "type": "kafka.javaapi.producer.Producer<String, String>", "declarator": "producer", "var_name": "producer"}], "file": "fabric-components/kafka-writer/src/test/java/com/olacabs/fabric/processors/kafkawriter/KafkaWriterTest.java"}, "test_case": {"identifier": "testConsume", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n    public void testConsume() throws Exception {\n        Random rnd = new Random();\n        ObjectMapper mapper = new ObjectMapper();\n        List<String> lst = Lists.newArrayList();\n        for (int i = 0; i < 5; i++) {\n            lst.add(\"{\\\"firstName\\\":\\\"\" + \"xyz\" + rnd.nextInt(10) + \"\\\", \\\"lastName\\\":\\\"Doe\" + rnd.nextInt(100)\n                    + \"\\\"}\");\n\n        }\n\n        ProcessorTestBench processorTestBench = new ProcessorTestBench(false);\n        List<EventSet> events = processorTestBench.runStreamingProcessor(processor, ImmutableList\n                .of(EventSet.eventFromEventBuilder().events(ImmutableList\n                                .of(Event.builder().jsonNode(mapper.readTree(lst.get(0))).build(),\n                                        Event.builder().jsonNode(mapper.readTree(lst.get(0))).build())).build(),\n                        EventSet.eventFromEventBuilder().events(ImmutableList\n                                .of(Event.builder().jsonNode(mapper.readTree(lst.get(0))).build(),\n                                        Event.builder().jsonNode(mapper.readTree(lst.get(0))).build(),\n                                        Event.builder().jsonNode(mapper.readTree(lst.get(0))).build())).build()));\n\n        verify(producer, times(2)).send(anyList());\n\n\n    }", "signature": "void testConsume()", "full_signature": "@Test public void testConsume()", "class_method_signature": "KafkaWriterTest.testConsume()", "testcase": true, "constructor": false, "invocations": ["newArrayList", "add", "nextInt", "nextInt", "runStreamingProcessor", "of", "build", "events", "eventFromEventBuilder", "of", "build", "jsonNode", "builder", "readTree", "get", "build", "jsonNode", "builder", "readTree", "get", "build", "events", "eventFromEventBuilder", "of", "build", "jsonNode", "builder", "readTree", "get", "build", "jsonNode", "builder", "readTree", "get", "build", "jsonNode", "builder", "readTree", "get", "send", "verify", "times", "anyList"]}, "focal_class": {"identifier": "KafkaWriter", "superclass": "extends StreamingProcessor", "interfaces": "", "fields": [{"original_string": "private static final Logger LOGGER = LoggerFactory.getLogger(KafkaWriter.class.getSimpleName());", "modifier": "private static final", "type": "Logger", "declarator": "LOGGER = LoggerFactory.getLogger(KafkaWriter.class.getSimpleName())", "var_name": "LOGGER"}, {"original_string": "private static final boolean DEFAULT_IGNORE_SERIALIZATION_ERROR = false;", "modifier": "private static final", "type": "boolean", "declarator": "DEFAULT_IGNORE_SERIALIZATION_ERROR = false", "var_name": "DEFAULT_IGNORE_SERIALIZATION_ERROR"}, {"original_string": "private static final boolean DEFAULT_TOPIC_ON_JSON_PATH = false;", "modifier": "private static final", "type": "boolean", "declarator": "DEFAULT_TOPIC_ON_JSON_PATH = false", "var_name": "DEFAULT_TOPIC_ON_JSON_PATH"}, {"original_string": "private static final String DEFAULT_SERIALIZER_CLASS = \"kafka.serializer.StringEncoder\";", "modifier": "private static final", "type": "String", "declarator": "DEFAULT_SERIALIZER_CLASS = \"kafka.serializer.StringEncoder\"", "var_name": "DEFAULT_SERIALIZER_CLASS"}, {"original_string": "private static final String DEFAULT_KAFKA_KEY_JSON_PATH = \"/metadata/partitionKey/value\";", "modifier": "private static final", "type": "String", "declarator": "DEFAULT_KAFKA_KEY_JSON_PATH = \"/metadata/partitionKey/value\"", "var_name": "DEFAULT_KAFKA_KEY_JSON_PATH"}, {"original_string": "private static final int DEFAULT_ACK_COUNT = 1;", "modifier": "private static final", "type": "int", "declarator": "DEFAULT_ACK_COUNT = 1", "var_name": "DEFAULT_ACK_COUNT"}, {"original_string": "private static final int DEFAULT_BATCH_SIZE = 10;", "modifier": "private static final", "type": "int", "declarator": "DEFAULT_BATCH_SIZE = 10", "var_name": "DEFAULT_BATCH_SIZE"}, {"original_string": "private static final String ACK_COUNT = \"-1\";", "modifier": "private static final", "type": "String", "declarator": "ACK_COUNT = \"-1\"", "var_name": "ACK_COUNT"}, {"original_string": "private String kafkaKeyJsonPath;", "modifier": "private", "type": "String", "declarator": "kafkaKeyJsonPath", "var_name": "kafkaKeyJsonPath"}, {"original_string": "private boolean ignoreError;", "modifier": "private", "type": "boolean", "declarator": "ignoreError", "var_name": "ignoreError"}, {"original_string": "private ObjectMapper mapper;", "modifier": "private", "type": "ObjectMapper", "declarator": "mapper", "var_name": "mapper"}, {"original_string": "@Getter\n    @Setter\n    private String kafkaTopic;", "modifier": "@Getter\n    @Setter\n    private", "type": "String", "declarator": "kafkaTopic", "var_name": "kafkaTopic"}, {"original_string": "@Getter\n    @Setter\n    private String kafkaTopicJsonPath;", "modifier": "@Getter\n    @Setter\n    private", "type": "String", "declarator": "kafkaTopicJsonPath", "var_name": "kafkaTopicJsonPath"}, {"original_string": "@Getter\n    @Setter\n    private int ingestionPoolSize;", "modifier": "@Getter\n    @Setter\n    private", "type": "int", "declarator": "ingestionPoolSize", "var_name": "ingestionPoolSize"}, {"original_string": "@Getter\n    @Setter\n    private Producer<String, String> producer;", "modifier": "@Getter\n    @Setter\n    private", "type": "Producer<String, String>", "declarator": "producer", "var_name": "producer"}, {"original_string": "@Getter\n    @Setter\n    private boolean isTopicOnJsonPath = false;", "modifier": "@Getter\n    @Setter\n    private", "type": "boolean", "declarator": "isTopicOnJsonPath = false", "var_name": "isTopicOnJsonPath"}], "methods": [{"identifier": "consume", "parameters": "(ProcessingContext processingContext, EventSet eventSet)", "modifiers": "@Override protected", "return": "EventSet", "signature": "EventSet consume(ProcessingContext processingContext, EventSet eventSet)", "full_signature": "@Override protected EventSet consume(ProcessingContext processingContext, EventSet eventSet)", "class_method_signature": "KafkaWriter.consume(ProcessingContext processingContext, EventSet eventSet)", "testcase": false, "constructor": false}, {"identifier": "convertEvent", "parameters": "(Event event)", "modifiers": "protected", "return": "KeyedMessage<String, String>", "signature": "KeyedMessage<String, String> convertEvent(Event event)", "full_signature": "protected KeyedMessage<String, String> convertEvent(Event event)", "class_method_signature": "KafkaWriter.convertEvent(Event event)", "testcase": false, "constructor": false}, {"identifier": "initialize", "parameters": "(String instanceId, Properties globalProperties, Properties properties,\n            ComponentMetadata componentMetadata)", "modifiers": "@Override public", "return": "void", "signature": "void initialize(String instanceId, Properties globalProperties, Properties properties,\n            ComponentMetadata componentMetadata)", "full_signature": "@Override public void initialize(String instanceId, Properties globalProperties, Properties properties,\n            ComponentMetadata componentMetadata)", "class_method_signature": "KafkaWriter.initialize(String instanceId, Properties globalProperties, Properties properties,\n            ComponentMetadata componentMetadata)", "testcase": false, "constructor": false}, {"identifier": "destroy", "parameters": "()", "modifiers": "@Override public", "return": "void", "signature": "void destroy()", "full_signature": "@Override public void destroy()", "class_method_signature": "KafkaWriter.destroy()", "testcase": false, "constructor": false}], "file": "fabric-components/kafka-writer/src/main/java/com/olacabs/fabric/processors/kafkawriter/KafkaWriter.java"}, "focal_method": {"identifier": "consume", "parameters": "(ProcessingContext processingContext, EventSet eventSet)", "modifiers": "@Override protected", "return": "EventSet", "body": "@Override\n    protected EventSet consume(ProcessingContext processingContext, EventSet eventSet) throws ProcessingException {\n        final List<KeyedMessage<String, String>> messages = Lists.newArrayList();\n        try {\n            eventSet.getEvents().forEach(event -> {\n                KeyedMessage<String, String> convertedMessage = null;\n                try {\n                    convertedMessage = convertEvent(event);\n                } catch (ProcessingException e) {\n                    LOGGER.error(\"Error converting byte stream to event: \", e);\n                    throw new RuntimeException(e);\n                }\n                if (null != convertedMessage) {\n                    messages.add(convertedMessage);\n                }\n            });\n        } catch (final Exception e) {\n            LOGGER.error(\"Error converting byte stream to event: \", e);\n            throw new ProcessingException(e);\n        }\n        Lists.partition(messages, ingestionPoolSize).forEach(messageList -> getProducer().send(messageList));\n        return eventSet;\n    }", "signature": "EventSet consume(ProcessingContext processingContext, EventSet eventSet)", "full_signature": "@Override protected EventSet consume(ProcessingContext processingContext, EventSet eventSet)", "class_method_signature": "KafkaWriter.consume(ProcessingContext processingContext, EventSet eventSet)", "testcase": false, "constructor": false, "invocations": ["newArrayList", "forEach", "getEvents", "convertEvent", "error", "add", "error", "forEach", "partition", "send", "getProducer"]}, "repository": {"repo_id": 71972621, "url": "https://github.com/olacabs/fabric", "language": "Java", "is_fork": false, "fork_count": 36, "stargazer_count": 43, "size": 234, "license": "licensed"}}