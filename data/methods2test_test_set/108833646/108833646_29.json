{"test_class": {"identifier": "OutputLayerTest", "superclass": "", "interfaces": "", "fields": [], "file": "deepnetts-core/src/test/java/deepnetts/net/layers/OutputLayerTest.java"}, "test_case": {"identifier": "testForward", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n    public void testForward() {\n        \n        RandomGenerator.getDefault().initSeed(123);         // initialize weights using specified random seed\n        Tensor input = new Tensor(0.1f, 0.2f, 0.3f, 0.4f, 0.5f); // input vector for this layer (output for previous layer)\n        Tensor weights = new Tensor(5, 10); \n        WeightsInit.uniform(weights.getValues(), 5); // \"[0.19961303, -0.23501621, 0.43907326, -0.17747784, -0.22066136, 0.06630343, 0.097314, -0.21566293, 0.273578, 0.10945064, 0.33577937, 0.044093937, 0.19323963, -0.3021235, -0.38288906, 0.16261822, 0.26498383, -0.207817, 0.070406556, -0.23022851, 0.36503863, 0.091478825, -0.31402034, -0.25345784, 0.42504954, -0.037393004, -0.38854277, -0.36758634, -0.38503492, -0.33786723, -0.36604232, -0.14479709, -0.06755906, 0.38639867, 0.3348655, 0.15910655, 0.06717491, -0.4455302, -0.09257606, -1.219213E-4, -0.21616945, 0.43006968, -0.31055218, 0.2699433, -0.214278, 0.25471163, -0.03427276, -0.43431506, -0.054469943, -0.23747501]\" \n\n       Tensor expectedOutputs = new Tensor( 0.51053022f, 0.59142921f, 0.52648754f, 0.56102458f, 0.54380692f, 0.58635918f, 0.54137987f, 0.41367945f, 0.52289978f, 0.4961883f );\n         \n        // create prev fc layer with 5 outputs\n        FullyConnectedLayer prevLayer = new FullyConnectedLayer(5);        \n        prevLayer.setOutputs(input); // and set its ouput that will be used as input for next layer\n                \n        // create instance of layer to test\n        OutputLayer instance = new OutputLayer(10);\n        instance.setPrevLayer(prevLayer);        \n        instance.init(); // init weights structures\n        instance.setWeights(weights); // set weights values\n        instance.setBiases(new float[] {0.1f, 0.2f, 0.3f, 0.11f, 0.12f, 0.13f, 0.21f, 0.22f, 0.23f, 0.24f}); // set bias values\n        \n        // run forward pass\n        instance.forward();\n        \n        // get layer outpputs\n        Tensor actualOutputs = instance.getOutputs();\n        \n        assertArrayEquals(actualOutputs.getValues(), expectedOutputs.getValues(), 1e-7f);\n    }", "signature": "void testForward()", "full_signature": "@Test public void testForward()", "class_method_signature": "OutputLayerTest.testForward()", "testcase": true, "constructor": false, "invocations": ["initSeed", "getDefault", "uniform", "getValues", "setOutputs", "setPrevLayer", "init", "setWeights", "setBiases", "forward", "getOutputs", "assertArrayEquals", "getValues", "getValues"]}, "focal_class": {"identifier": "OutputLayer", "superclass": "extends AbstractLayer", "interfaces": "", "fields": [{"original_string": "protected float[] outputErrors;", "modifier": "protected", "type": "float[]", "declarator": "outputErrors", "var_name": "outputErrors"}, {"original_string": "protected final String[] labels;", "modifier": "protected final", "type": "String[]", "declarator": "labels", "var_name": "labels"}, {"original_string": "protected LossType lossType;", "modifier": "protected", "type": "LossType", "declarator": "lossType", "var_name": "lossType"}, {"original_string": "int targetClassIdx;", "modifier": "", "type": "int", "declarator": "targetClassIdx", "var_name": "targetClassIdx"}], "methods": [{"identifier": "OutputLayer", "parameters": "(int width)", "modifiers": "public", "return": "", "signature": " OutputLayer(int width)", "full_signature": "public  OutputLayer(int width)", "class_method_signature": "OutputLayer.OutputLayer(int width)", "testcase": false, "constructor": true}, {"identifier": "OutputLayer", "parameters": "(int width, ActivationType activationFunction)", "modifiers": "public", "return": "", "signature": " OutputLayer(int width, ActivationType activationFunction)", "full_signature": "public  OutputLayer(int width, ActivationType activationFunction)", "class_method_signature": "OutputLayer.OutputLayer(int width, ActivationType activationFunction)", "testcase": false, "constructor": true}, {"identifier": "OutputLayer", "parameters": "(String[] labels)", "modifiers": "public", "return": "", "signature": " OutputLayer(String[] labels)", "full_signature": "public  OutputLayer(String[] labels)", "class_method_signature": "OutputLayer.OutputLayer(String[] labels)", "testcase": false, "constructor": true}, {"identifier": "OutputLayer", "parameters": "(String[] labels, ActivationType activationFunction)", "modifiers": "public", "return": "", "signature": " OutputLayer(String[] labels, ActivationType activationFunction)", "full_signature": "public  OutputLayer(String[] labels, ActivationType activationFunction)", "class_method_signature": "OutputLayer.OutputLayer(String[] labels, ActivationType activationFunction)", "testcase": false, "constructor": true}, {"identifier": "setOutputErrors", "parameters": "(final float[] outputErrors)", "modifiers": "public final", "return": "void", "signature": "void setOutputErrors(final float[] outputErrors)", "full_signature": "public final void setOutputErrors(final float[] outputErrors)", "class_method_signature": "OutputLayer.setOutputErrors(final float[] outputErrors)", "testcase": false, "constructor": false}, {"identifier": "getOutputErrors", "parameters": "()", "modifiers": "public final", "return": "float[]", "signature": "float[] getOutputErrors()", "full_signature": "public final float[] getOutputErrors()", "class_method_signature": "OutputLayer.getOutputErrors()", "testcase": false, "constructor": false}, {"identifier": "getLossType", "parameters": "()", "modifiers": "public final", "return": "LossType", "signature": "LossType getLossType()", "full_signature": "public final LossType getLossType()", "class_method_signature": "OutputLayer.getLossType()", "testcase": false, "constructor": false}, {"identifier": "setLossType", "parameters": "(LossType lossType)", "modifiers": "public", "return": "void", "signature": "void setLossType(LossType lossType)", "full_signature": "public void setLossType(LossType lossType)", "class_method_signature": "OutputLayer.setLossType(LossType lossType)", "testcase": false, "constructor": false}, {"identifier": "init", "parameters": "()", "modifiers": "@Override public", "return": "void", "signature": "void init()", "full_signature": "@Override public void init()", "class_method_signature": "OutputLayer.init()", "testcase": false, "constructor": false}, {"identifier": "forward", "parameters": "()", "modifiers": "@Override public", "return": "void", "signature": "void forward()", "full_signature": "@Override public void forward()", "class_method_signature": "OutputLayer.forward()", "testcase": false, "constructor": false}, {"identifier": "backward", "parameters": "()", "modifiers": "@Override public", "return": "void", "signature": "void backward()", "full_signature": "@Override public void backward()", "class_method_signature": "OutputLayer.backward()", "testcase": false, "constructor": false}, {"identifier": "applyWeightChanges", "parameters": "()", "modifiers": "@Override public", "return": "void", "signature": "void applyWeightChanges()", "full_signature": "@Override public void applyWeightChanges()", "class_method_signature": "OutputLayer.applyWeightChanges()", "testcase": false, "constructor": false}], "file": "deepnetts-core/src/main/java/deepnetts/net/layers/OutputLayer.java"}, "focal_method": {"identifier": "forward", "parameters": "()", "modifiers": "@Override public", "return": "void", "body": "@Override\n    public void forward() {                \n        outputs.copyFrom(biases);  // reset output to bias value        \n        for (int outCol = 0; outCol < outputs.getCols(); outCol++) {  // for all neurons in this layer  | ForkJoin split this in two until you reach size which makes sense: number of calculations = inputCols * outputCols           \n            for (int inCol = 0; inCol < inputs.getCols(); inCol++) {\n                outputs.add(outCol, inputs.get(inCol) * weights.get(inCol, outCol));    // add weighted sum\n            }                        \n            //outputs.set(outCol, ActivationFunctions.sigmoid(outputs.get(outCol)));      // apply activation function - could be tanh too\n            outputs.set(outCol, ActivationFunctions.calc(activationType, outputs.get(outCol)));\n        }             \n    }", "signature": "void forward()", "full_signature": "@Override public void forward()", "class_method_signature": "OutputLayer.forward()", "testcase": false, "constructor": false, "invocations": ["copyFrom", "getCols", "getCols", "add", "get", "get", "set", "calc", "get"]}, "repository": {"repo_id": 108833646, "url": "https://github.com/sevarac/deepnetts", "language": "Java", "is_fork": false, "fork_count": 3, "stargazer_count": 8, "size": 5220, "license": "licensed"}}