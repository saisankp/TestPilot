{"test_class": {"identifier": "QualityAnalysisTest", "superclass": "extends DataSetBaseTest", "interfaces": "", "fields": [{"original_string": "@Autowired\n    FormatAnalysis formatAnalysis;", "modifier": "@Autowired", "type": "FormatAnalysis", "declarator": "formatAnalysis", "var_name": "formatAnalysis"}, {"original_string": "@Autowired\n    QualityAnalysis qualityAnalysis;", "modifier": "@Autowired", "type": "QualityAnalysis", "declarator": "qualityAnalysis", "var_name": "qualityAnalysis"}, {"original_string": "@Autowired\n    SchemaAnalysis schemaAnalysis;", "modifier": "@Autowired", "type": "SchemaAnalysis", "declarator": "schemaAnalysis", "var_name": "schemaAnalysis"}, {"original_string": "@Autowired\n    ContentAnalysis contentAnalysis;", "modifier": "@Autowired", "type": "ContentAnalysis", "declarator": "contentAnalysis", "var_name": "contentAnalysis"}, {"original_string": "private Random random = new Random();", "modifier": "private", "type": "Random", "declarator": "random = new Random()", "var_name": "random"}], "file": "dataprep-dataset/src/test/java/org/talend/dataprep/dataset/service/analysis/synchronous/QualityAnalysisTest.java"}, "test_case": {"identifier": "testAnalysis", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n    public void testAnalysis() {\n        String id = UUID.randomUUID().toString();\n        final DataSetMetadata metadata = metadataBuilder.metadata().id(id).build();\n        dataSetMetadataRepository.save(metadata);\n        contentStore.storeAsRaw(metadata, DataSetServiceTest.class.getResourceAsStream(\"../avengers.csv\"));\n        formatAnalysis.analyze(id);\n        contentAnalysis.analyze(id);\n        schemaAnalysis.analyze(id);\n        // Analyze quality\n        qualityAnalysis.analyze(id);\n        final DataSetMetadata actual = dataSetMetadataRepository.get(id);\n        assertThat(actual.getLifecycle().qualityAnalyzed(), is(true));\n        assertThat(actual.getContent().getNbRecords(), is(5L));\n        for (ColumnMetadata column : actual.getRowMetadata().getColumns()) {\n            final Quality quality = column.getQuality();\n            assertThat(quality.getValid(), is(5));\n            assertThat(quality.getInvalid(), is(0));\n            assertThat(quality.getEmpty(), is(0));\n        }\n    }", "signature": "void testAnalysis()", "full_signature": "@Test public void testAnalysis()", "class_method_signature": "QualityAnalysisTest.testAnalysis()", "testcase": true, "constructor": false, "invocations": ["toString", "randomUUID", "build", "id", "metadata", "save", "storeAsRaw", "getResourceAsStream", "analyze", "analyze", "analyze", "analyze", "get", "assertThat", "qualityAnalyzed", "getLifecycle", "is", "assertThat", "getNbRecords", "getContent", "is", "getColumns", "getRowMetadata", "getQuality", "assertThat", "getValid", "is", "assertThat", "getInvalid", "is", "assertThat", "getEmpty", "is"]}, "focal_class": {"identifier": "QualityAnalysis", "superclass": "", "interfaces": "implements SynchronousDataSetAnalyzer", "fields": [{"original_string": "private static final Logger LOGGER = LoggerFactory.getLogger(QualityAnalysis.class);", "modifier": "private static final", "type": "Logger", "declarator": "LOGGER = LoggerFactory.getLogger(QualityAnalysis.class)", "var_name": "LOGGER"}, {"original_string": "@Autowired\n    DataSetMetadataRepository repository;", "modifier": "@Autowired", "type": "DataSetMetadataRepository", "declarator": "repository", "var_name": "repository"}, {"original_string": "@Autowired\n    ContentStoreRouter store;", "modifier": "@Autowired", "type": "ContentStoreRouter", "declarator": "store", "var_name": "store"}, {"original_string": "@Autowired\n    StatisticsAdapter adapter;", "modifier": "@Autowired", "type": "StatisticsAdapter", "declarator": "adapter", "var_name": "adapter"}, {"original_string": "@Autowired\n    AnalyzerService analyzerService;", "modifier": "@Autowired", "type": "AnalyzerService", "declarator": "analyzerService", "var_name": "analyzerService"}, {"original_string": "@Value(\"#{'${max_records:2000}'}\")\n    private final int maxRecord = 2000;", "modifier": "@Value(\"#{'${max_records:2000}'}\")\n    private final", "type": "int", "declarator": "maxRecord = 2000", "var_name": "maxRecord"}], "methods": [{"identifier": "analyze", "parameters": "(String dataSetId)", "modifiers": "@Override public", "return": "void", "signature": "void analyze(String dataSetId)", "full_signature": "@Override public void analyze(String dataSetId)", "class_method_signature": "QualityAnalysis.analyze(String dataSetId)", "testcase": false, "constructor": false}, {"identifier": "order", "parameters": "()", "modifiers": "@Override public", "return": "int", "signature": "int order()", "full_signature": "@Override public int order()", "class_method_signature": "QualityAnalysis.order()", "testcase": false, "constructor": false}, {"identifier": "computeQuality", "parameters": "(DataSetMetadata dataset, Stream<DataSetRow> records, long limit)", "modifiers": "public", "return": "void", "signature": "void computeQuality(DataSetMetadata dataset, Stream<DataSetRow> records, long limit)", "full_signature": "public void computeQuality(DataSetMetadata dataset, Stream<DataSetRow> records, long limit)", "class_method_signature": "QualityAnalysis.computeQuality(DataSetMetadata dataset, Stream<DataSetRow> records, long limit)", "testcase": false, "constructor": false}], "file": "dataprep-dataset/src/main/java/org/talend/dataprep/dataset/service/analysis/synchronous/QualityAnalysis.java"}, "focal_method": {"identifier": "analyze", "parameters": "(String dataSetId)", "modifiers": "@Override public", "return": "void", "body": "@Override\n    public void analyze(String dataSetId) {\n        if (StringUtils.isEmpty(dataSetId)) {\n            throw new IllegalArgumentException(\"Data set id cannot be null or empty.\");\n        }\n        DistributedLock datasetLock = repository.createDatasetMetadataLock(dataSetId);\n        datasetLock.lock();\n        try {\n            DataSetMetadata metadata = repository.get(dataSetId);\n            if (metadata == null) {\n                LOGGER.info(\"Unable to analyze quality of data set #{}: seems to be removed.\", dataSetId);\n                return;\n            }\n            // e.g. excel multi sheet dataset when user has not choose the sheet yet\n            if (!metadata.getLifecycle().isInProgress()) {\n                LOGGER.debug(\"No need to recompute quality of data set #{} (statistics are completed).\", dataSetId);\n                return;\n            }\n            if (!metadata.getLifecycle().schemaAnalyzed()) {\n                LOGGER.debug(\n                        \"Schema information must be computed before quality analysis can be performed, ignoring message\");\n                return; // no acknowledge to allow re-poll.\n            }\n\n            try (Stream<DataSetRow> stream = store.stream(metadata)) {\n\n                LOGGER.debug(\"Analyzing quality of dataset #{}...\", metadata.getId());\n                // New data set, or reached the max limit of records for synchronous analysis, trigger a full scan (but\n                // async).\n                final long dataSetSize = metadata.getContent().getNbRecords();\n                final boolean isNewDataSet = dataSetSize == 0;\n                if (isNewDataSet || dataSetSize == maxRecord) {\n                    // If data set size is maxRecord, performs a full scan, otherwise only take first maxRecord\n                    // records.\n                    computeQuality(metadata, stream, dataSetSize == maxRecord ? -1 : maxRecord);\n                }\n                // Turn on / off \"in progress\" flag\n                if (isNewDataSet && metadata.getContent().getNbRecords() >= maxRecord) {\n                    metadata.getLifecycle().setInProgress(true);\n                } else {\n                    metadata.getLifecycle().setInProgress(false);\n                }\n                // ... all quality is now analyzed, mark it so.\n                metadata.getLifecycle().qualityAnalyzed(true);\n                final DataSetMetadata savedDataSetMetadata = repository.get(metadata.getId());\n                // in order to check that the dataset was not deleted during analysis\n                if (savedDataSetMetadata != null) {\n                    repository.save(metadata);\n                    LOGGER.debug(\"Analyzed quality of dataset #{}.\", dataSetId);\n                }\n\n            } catch (Exception e) {\n                LOGGER.warn(\"dataset '{}' generate an error, message: {} \", dataSetId, e.getMessage());\n                throw new TDPException(DataSetErrorCodes.UNABLE_TO_ANALYZE_DATASET_QUALITY, e);\n            }\n        } finally {\n            datasetLock.unlock();\n        }\n    }", "signature": "void analyze(String dataSetId)", "full_signature": "@Override public void analyze(String dataSetId)", "class_method_signature": "QualityAnalysis.analyze(String dataSetId)", "testcase": false, "constructor": false, "invocations": ["isEmpty", "createDatasetMetadataLock", "lock", "get", "info", "isInProgress", "getLifecycle", "debug", "schemaAnalyzed", "getLifecycle", "debug", "stream", "debug", "getId", "getNbRecords", "getContent", "computeQuality", "getNbRecords", "getContent", "setInProgress", "getLifecycle", "setInProgress", "getLifecycle", "qualityAnalyzed", "getLifecycle", "get", "getId", "save", "debug", "warn", "getMessage", "unlock"]}, "repository": {"repo_id": 26644682, "url": "https://github.com/Talend/data-prep", "language": "Java", "is_fork": false, "fork_count": 29, "stargazer_count": 53, "size": 70450, "license": "licensed"}}