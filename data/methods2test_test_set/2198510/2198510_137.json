{"test_class": {"identifier": "TestKafkaSource", "superclass": "", "interfaces": "", "fields": [{"original_string": "private static final Logger log = LoggerFactory.getLogger(TestKafkaSource.class);", "modifier": "private static final", "type": "Logger", "declarator": "log = LoggerFactory.getLogger(TestKafkaSource.class)", "var_name": "log"}, {"original_string": "private KafkaSource kafkaSource;", "modifier": "private", "type": "KafkaSource", "declarator": "kafkaSource", "var_name": "kafkaSource"}, {"original_string": "private static KafkaSourceEmbeddedKafka kafkaServer;", "modifier": "private static", "type": "KafkaSourceEmbeddedKafka", "declarator": "kafkaServer", "var_name": "kafkaServer"}, {"original_string": "private Context context;", "modifier": "private", "type": "Context", "declarator": "context", "var_name": "context"}, {"original_string": "private List<Event> events;", "modifier": "private", "type": "List<Event>", "declarator": "events", "var_name": "events"}, {"original_string": "private final List<String> usedTopics = new ArrayList<>();", "modifier": "private final", "type": "List<String>", "declarator": "usedTopics = new ArrayList<>()", "var_name": "usedTopics"}, {"original_string": "private String topic0;", "modifier": "private", "type": "String", "declarator": "topic0", "var_name": "topic0"}, {"original_string": "private String topic1;", "modifier": "private", "type": "String", "declarator": "topic1", "var_name": "topic1"}], "file": "flume-ng-sources/flume-kafka-source/src/test/java/org/apache/flume/source/kafka/TestKafkaSource.java"}, "test_case": {"identifier": "testMigrateZookeeperOffsetsWhenTopicNotExists", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n  public void testMigrateZookeeperOffsetsWhenTopicNotExists() throws Exception {\n    String topic = findUnusedTopic();\n\n    Context context = prepareDefaultContext(\"testMigrateOffsets-nonExistingTopic\");\n    context.put(ZOOKEEPER_CONNECT_FLUME_KEY, kafkaServer.getZkConnectString());\n    context.put(TOPIC, topic);\n    KafkaSource source = new KafkaSource();\n    source.doConfigure(context);\n\n    source.setChannelProcessor(createGoodChannel());\n    source.start();\n\n    assertEquals(LifecycleState.START, source.getLifecycleState());\n\n    Status status = source.process();\n    assertEquals(Status.BACKOFF, status);\n\n    source.stop();\n  }", "signature": "void testMigrateZookeeperOffsetsWhenTopicNotExists()", "full_signature": "@Test public void testMigrateZookeeperOffsetsWhenTopicNotExists()", "class_method_signature": "TestKafkaSource.testMigrateZookeeperOffsetsWhenTopicNotExists()", "testcase": true, "constructor": false, "invocations": ["findUnusedTopic", "prepareDefaultContext", "put", "getZkConnectString", "put", "doConfigure", "setChannelProcessor", "createGoodChannel", "start", "assertEquals", "getLifecycleState", "process", "assertEquals", "stop"]}, "focal_class": {"identifier": "KafkaSource", "superclass": "extends AbstractPollableSource", "interfaces": "implements Configurable, BatchSizeSupported", "fields": [{"original_string": "private static final Logger log = LoggerFactory.getLogger(KafkaSource.class);", "modifier": "private static final", "type": "Logger", "declarator": "log = LoggerFactory.getLogger(KafkaSource.class)", "var_name": "log"}, {"original_string": "private static final int ZK_SESSION_TIMEOUT = 30000;", "modifier": "private static final", "type": "int", "declarator": "ZK_SESSION_TIMEOUT = 30000", "var_name": "ZK_SESSION_TIMEOUT"}, {"original_string": "private static final int ZK_CONNECTION_TIMEOUT = 30000;", "modifier": "private static final", "type": "int", "declarator": "ZK_CONNECTION_TIMEOUT = 30000", "var_name": "ZK_CONNECTION_TIMEOUT"}, {"original_string": "private Context context;", "modifier": "private", "type": "Context", "declarator": "context", "var_name": "context"}, {"original_string": "private Properties kafkaProps;", "modifier": "private", "type": "Properties", "declarator": "kafkaProps", "var_name": "kafkaProps"}, {"original_string": "private KafkaSourceCounter counter;", "modifier": "private", "type": "KafkaSourceCounter", "declarator": "counter", "var_name": "counter"}, {"original_string": "private KafkaConsumer<String, byte[]> consumer;", "modifier": "private", "type": "KafkaConsumer<String, byte[]>", "declarator": "consumer", "var_name": "consumer"}, {"original_string": "private Iterator<ConsumerRecord<String, byte[]>> it;", "modifier": "private", "type": "Iterator<ConsumerRecord<String, byte[]>>", "declarator": "it", "var_name": "it"}, {"original_string": "private final List<Event> eventList = new ArrayList<Event>();", "modifier": "private final", "type": "List<Event>", "declarator": "eventList = new ArrayList<Event>()", "var_name": "eventList"}, {"original_string": "private Map<TopicPartition, OffsetAndMetadata> tpAndOffsetMetadata;", "modifier": "private", "type": "Map<TopicPartition, OffsetAndMetadata>", "declarator": "tpAndOffsetMetadata", "var_name": "tpAndOffsetMetadata"}, {"original_string": "private AtomicBoolean rebalanceFlag;", "modifier": "private", "type": "AtomicBoolean", "declarator": "rebalanceFlag", "var_name": "rebalanceFlag"}, {"original_string": "private Map<String, String> headers;", "modifier": "private", "type": "Map<String, String>", "declarator": "headers", "var_name": "headers"}, {"original_string": "private Optional<SpecificDatumReader<AvroFlumeEvent>> reader = Optional.absent();", "modifier": "private", "type": "Optional<SpecificDatumReader<AvroFlumeEvent>>", "declarator": "reader = Optional.absent()", "var_name": "reader"}, {"original_string": "private BinaryDecoder decoder = null;", "modifier": "private", "type": "BinaryDecoder", "declarator": "decoder = null", "var_name": "decoder"}, {"original_string": "private boolean useAvroEventFormat;", "modifier": "private", "type": "boolean", "declarator": "useAvroEventFormat", "var_name": "useAvroEventFormat"}, {"original_string": "private int batchUpperLimit;", "modifier": "private", "type": "int", "declarator": "batchUpperLimit", "var_name": "batchUpperLimit"}, {"original_string": "private int maxBatchDurationMillis;", "modifier": "private", "type": "int", "declarator": "maxBatchDurationMillis", "var_name": "maxBatchDurationMillis"}, {"original_string": "private Subscriber subscriber;", "modifier": "private", "type": "Subscriber", "declarator": "subscriber", "var_name": "subscriber"}, {"original_string": "private String zookeeperConnect;", "modifier": "private", "type": "String", "declarator": "zookeeperConnect", "var_name": "zookeeperConnect"}, {"original_string": "private String bootstrapServers;", "modifier": "private", "type": "String", "declarator": "bootstrapServers", "var_name": "bootstrapServers"}, {"original_string": "private String groupId = DEFAULT_GROUP_ID;", "modifier": "private", "type": "String", "declarator": "groupId = DEFAULT_GROUP_ID", "var_name": "groupId"}, {"original_string": "@Deprecated\n  private boolean migrateZookeeperOffsets = DEFAULT_MIGRATE_ZOOKEEPER_OFFSETS;", "modifier": "@Deprecated\n  private", "type": "boolean", "declarator": "migrateZookeeperOffsets = DEFAULT_MIGRATE_ZOOKEEPER_OFFSETS", "var_name": "migrateZookeeperOffsets"}, {"original_string": "private String topicHeader = null;", "modifier": "private", "type": "String", "declarator": "topicHeader = null", "var_name": "topicHeader"}, {"original_string": "private boolean setTopicHeader;", "modifier": "private", "type": "boolean", "declarator": "setTopicHeader", "var_name": "setTopicHeader"}], "methods": [{"identifier": "getBatchSize", "parameters": "()", "modifiers": "@Override public", "return": "long", "signature": "long getBatchSize()", "full_signature": "@Override public long getBatchSize()", "class_method_signature": "KafkaSource.getBatchSize()", "testcase": false, "constructor": false}, {"identifier": "doProcess", "parameters": "()", "modifiers": "@Override protected", "return": "Status", "signature": "Status doProcess()", "full_signature": "@Override protected Status doProcess()", "class_method_signature": "KafkaSource.doProcess()", "testcase": false, "constructor": false}, {"identifier": "doConfigure", "parameters": "(Context context)", "modifiers": "@Override protected", "return": "void", "signature": "void doConfigure(Context context)", "full_signature": "@Override protected void doConfigure(Context context)", "class_method_signature": "KafkaSource.doConfigure(Context context)", "testcase": false, "constructor": false}, {"identifier": "translateOldProperties", "parameters": "(Context ctx)", "modifiers": "private", "return": "void", "signature": "void translateOldProperties(Context ctx)", "full_signature": "private void translateOldProperties(Context ctx)", "class_method_signature": "KafkaSource.translateOldProperties(Context ctx)", "testcase": false, "constructor": false}, {"identifier": "setConsumerProps", "parameters": "(Context ctx)", "modifiers": "private", "return": "void", "signature": "void setConsumerProps(Context ctx)", "full_signature": "private void setConsumerProps(Context ctx)", "class_method_signature": "KafkaSource.setConsumerProps(Context ctx)", "testcase": false, "constructor": false}, {"identifier": "lookupBootstrap", "parameters": "(String zookeeperConnect, SecurityProtocol securityProtocol)", "modifiers": "private", "return": "String", "signature": "String lookupBootstrap(String zookeeperConnect, SecurityProtocol securityProtocol)", "full_signature": "private String lookupBootstrap(String zookeeperConnect, SecurityProtocol securityProtocol)", "class_method_signature": "KafkaSource.lookupBootstrap(String zookeeperConnect, SecurityProtocol securityProtocol)", "testcase": false, "constructor": false}, {"identifier": "getBootstrapServers", "parameters": "()", "modifiers": "@VisibleForTesting", "return": "String", "signature": "String getBootstrapServers()", "full_signature": "@VisibleForTesting String getBootstrapServers()", "class_method_signature": "KafkaSource.getBootstrapServers()", "testcase": false, "constructor": false}, {"identifier": "getConsumerProps", "parameters": "()", "modifiers": "", "return": "Properties", "signature": "Properties getConsumerProps()", "full_signature": " Properties getConsumerProps()", "class_method_signature": "KafkaSource.getConsumerProps()", "testcase": false, "constructor": false}, {"identifier": "toStringMap", "parameters": "(Map<CharSequence, CharSequence> charSeqMap)", "modifiers": "private static", "return": "Map<String, String>", "signature": "Map<String, String> toStringMap(Map<CharSequence, CharSequence> charSeqMap)", "full_signature": "private static Map<String, String> toStringMap(Map<CharSequence, CharSequence> charSeqMap)", "class_method_signature": "KafkaSource.toStringMap(Map<CharSequence, CharSequence> charSeqMap)", "testcase": false, "constructor": false}, {"identifier": "getSubscriber", "parameters": "()", "modifiers": "", "return": "Subscriber<T>", "signature": "Subscriber<T> getSubscriber()", "full_signature": " Subscriber<T> getSubscriber()", "class_method_signature": "KafkaSource.getSubscriber()", "testcase": false, "constructor": false}, {"identifier": "doStart", "parameters": "()", "modifiers": "@Override protected", "return": "void", "signature": "void doStart()", "full_signature": "@Override protected void doStart()", "class_method_signature": "KafkaSource.doStart()", "testcase": false, "constructor": false}, {"identifier": "doStop", "parameters": "()", "modifiers": "@Override protected", "return": "void", "signature": "void doStop()", "full_signature": "@Override protected void doStop()", "class_method_signature": "KafkaSource.doStop()", "testcase": false, "constructor": false}, {"identifier": "migrateOffsets", "parameters": "(String topicStr)", "modifiers": "private", "return": "void", "signature": "void migrateOffsets(String topicStr)", "full_signature": "private void migrateOffsets(String topicStr)", "class_method_signature": "KafkaSource.migrateOffsets(String topicStr)", "testcase": false, "constructor": false}, {"identifier": "getKafkaOffsets", "parameters": "(\n      KafkaConsumer<String, byte[]> client, String topicStr)", "modifiers": "private", "return": "Map<TopicPartition, OffsetAndMetadata>", "signature": "Map<TopicPartition, OffsetAndMetadata> getKafkaOffsets(\n      KafkaConsumer<String, byte[]> client, String topicStr)", "full_signature": "private Map<TopicPartition, OffsetAndMetadata> getKafkaOffsets(\n      KafkaConsumer<String, byte[]> client, String topicStr)", "class_method_signature": "KafkaSource.getKafkaOffsets(\n      KafkaConsumer<String, byte[]> client, String topicStr)", "testcase": false, "constructor": false}, {"identifier": "getZookeeperOffsets", "parameters": "(\n          KafkaZkClient zkClient, KafkaConsumer<String, byte[]> consumer, String topicStr)", "modifiers": "private", "return": "Map<TopicPartition, OffsetAndMetadata>", "signature": "Map<TopicPartition, OffsetAndMetadata> getZookeeperOffsets(\n          KafkaZkClient zkClient, KafkaConsumer<String, byte[]> consumer, String topicStr)", "full_signature": "private Map<TopicPartition, OffsetAndMetadata> getZookeeperOffsets(\n          KafkaZkClient zkClient, KafkaConsumer<String, byte[]> consumer, String topicStr)", "class_method_signature": "KafkaSource.getZookeeperOffsets(\n          KafkaZkClient zkClient, KafkaConsumer<String, byte[]> consumer, String topicStr)", "testcase": false, "constructor": false}], "file": "flume-ng-sources/flume-kafka-source/src/main/java/org/apache/flume/source/kafka/KafkaSource.java"}, "focal_method": {"identifier": "doConfigure", "parameters": "(Context context)", "modifiers": "@Override protected", "return": "void", "body": "@Override\n  protected void doConfigure(Context context) throws FlumeException {\n    this.context = context;\n    headers = new HashMap<String, String>(4);\n    tpAndOffsetMetadata = new HashMap<TopicPartition, OffsetAndMetadata>();\n    rebalanceFlag = new AtomicBoolean(false);\n    kafkaProps = new Properties();\n\n    // can be removed in the next release\n    // See https://issues.apache.org/jira/browse/FLUME-2896\n    translateOldProperties(context);\n\n    String topicProperty = context.getString(KafkaSourceConstants.TOPICS_REGEX);\n    if (topicProperty != null && !topicProperty.isEmpty()) {\n      // create subscriber that uses pattern-based subscription\n      subscriber = new PatternSubscriber(topicProperty);\n    } else if ((topicProperty = context.getString(KafkaSourceConstants.TOPICS)) != null &&\n               !topicProperty.isEmpty()) {\n      // create subscriber that uses topic list subscription\n      subscriber = new TopicListSubscriber(topicProperty);\n    } else if (subscriber == null) {\n      throw new ConfigurationException(\"At least one Kafka topic must be specified.\");\n    }\n\n    batchUpperLimit = context.getInteger(KafkaSourceConstants.BATCH_SIZE,\n                                         KafkaSourceConstants.DEFAULT_BATCH_SIZE);\n    maxBatchDurationMillis = context.getInteger(KafkaSourceConstants.BATCH_DURATION_MS,\n                                                KafkaSourceConstants.DEFAULT_BATCH_DURATION);\n\n    useAvroEventFormat = context.getBoolean(KafkaSourceConstants.AVRO_EVENT,\n                                            KafkaSourceConstants.DEFAULT_AVRO_EVENT);\n\n    if (log.isDebugEnabled()) {\n      log.debug(KafkaSourceConstants.AVRO_EVENT + \" set to: {}\", useAvroEventFormat);\n    }\n\n    zookeeperConnect = context.getString(ZOOKEEPER_CONNECT_FLUME_KEY);\n    migrateZookeeperOffsets = context.getBoolean(MIGRATE_ZOOKEEPER_OFFSETS,\n        DEFAULT_MIGRATE_ZOOKEEPER_OFFSETS);\n\n    bootstrapServers = context.getString(KafkaSourceConstants.BOOTSTRAP_SERVERS);\n    if (bootstrapServers == null || bootstrapServers.isEmpty()) {\n      if (zookeeperConnect == null || zookeeperConnect.isEmpty()) {\n        throw new ConfigurationException(\"Bootstrap Servers must be specified\");\n      } else {\n        // For backwards compatibility look up the bootstrap from zookeeper\n        log.warn(\"{} is deprecated. Please use the parameter {}\",\n            KafkaSourceConstants.ZOOKEEPER_CONNECT_FLUME_KEY,\n            KafkaSourceConstants.BOOTSTRAP_SERVERS);\n\n        // Lookup configured security protocol, just in case its not default\n        String securityProtocolStr =\n            context.getSubProperties(KafkaSourceConstants.KAFKA_CONSUMER_PREFIX)\n                .get(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG);\n        if (securityProtocolStr == null || securityProtocolStr.isEmpty()) {\n          securityProtocolStr = CommonClientConfigs.DEFAULT_SECURITY_PROTOCOL;\n        }\n        bootstrapServers =\n            lookupBootstrap(zookeeperConnect, SecurityProtocol.valueOf(securityProtocolStr));\n      }\n    }\n\n    String groupIdProperty =\n        context.getString(KAFKA_CONSUMER_PREFIX + ConsumerConfig.GROUP_ID_CONFIG);\n    if (groupIdProperty != null && !groupIdProperty.isEmpty()) {\n      groupId = groupIdProperty; // Use the new group id property\n    }\n\n    if (groupId == null || groupId.isEmpty()) {\n      groupId = DEFAULT_GROUP_ID;\n      log.info(\"Group ID was not specified. Using {} as the group id.\", groupId);\n    }\n\n    setTopicHeader = context.getBoolean(KafkaSourceConstants.SET_TOPIC_HEADER,\n                                        KafkaSourceConstants.DEFAULT_SET_TOPIC_HEADER);\n\n    topicHeader = context.getString(KafkaSourceConstants.TOPIC_HEADER,\n                                    KafkaSourceConstants.DEFAULT_TOPIC_HEADER);\n\n    setConsumerProps(context);\n\n    if (log.isDebugEnabled() && LogPrivacyUtil.allowLogPrintConfig()) {\n      log.debug(\"Kafka consumer properties: {}\", kafkaProps);\n    }\n\n    if (counter == null) {\n      counter = new KafkaSourceCounter(getName());\n    }\n  }", "signature": "void doConfigure(Context context)", "full_signature": "@Override protected void doConfigure(Context context)", "class_method_signature": "KafkaSource.doConfigure(Context context)", "testcase": false, "constructor": false, "invocations": ["translateOldProperties", "getString", "isEmpty", "getString", "isEmpty", "getInteger", "getInteger", "getBoolean", "isDebugEnabled", "debug", "getString", "getBoolean", "getString", "isEmpty", "isEmpty", "warn", "get", "getSubProperties", "isEmpty", "lookupBootstrap", "valueOf", "getString", "isEmpty", "isEmpty", "info", "getBoolean", "getString", "setConsumerProps", "isDebugEnabled", "allowLogPrintConfig", "debug", "getName"]}, "repository": {"repo_id": 2198510, "url": "https://github.com/apache/flume", "language": "Java", "is_fork": false, "fork_count": 1372, "stargazer_count": 1971, "size": 44377, "license": "licensed"}}