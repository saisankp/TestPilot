{"test_class": {"identifier": "HadoopInputFormatTest", "superclass": "", "interfaces": "", "fields": [], "file": "flink-java/src/test/java/org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatTest.java"}, "test_case": {"identifier": "checkTypeInformation", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n\tpublic void checkTypeInformation() {\n\t\ttry {\n\t\t\t// Set up the Hadoop Input Format\n\t\t\tJob job = Job.getInstance();\n\t\t\tHadoopInputFormat<Void, Long> hadoopInputFormat = new HadoopInputFormat<Void, Long>(\n\t\t\t\t\tnew DummyVoidKeyInputFormat<Long>(), Void.class, Long.class, job);\n\n\t\t\tTypeInformation<Tuple2<Void,Long>> tupleType = hadoopInputFormat.getProducedType();\n\t\t\tTypeInformation<Tuple2<Void,Long>> testTupleType = new TupleTypeInfo<Tuple2<Void,Long>>(BasicTypeInfo.VOID_TYPE_INFO, BasicTypeInfo.LONG_TYPE_INFO);\n\t\t\t\n\t\t\tif(tupleType.isTupleType()) {\n\t\t\t\tif(!((TupleTypeInfo<?>)tupleType).equals(testTupleType)) {\n\t\t\t\t\tfail(\"Tuple type information was not set correctly!\");\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfail(\"Type information was not set to tuple type information!\");\n\t\t\t}\n\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tfail(\"Test failed due to a \" + ex.getClass().getSimpleName() + \": \" + ex.getMessage());\n\t\t}\n\t}", "signature": "void checkTypeInformation()", "full_signature": "@Test public void checkTypeInformation()", "class_method_signature": "HadoopInputFormatTest.checkTypeInformation()", "testcase": true, "constructor": false, "invocations": ["getInstance", "getProducedType", "isTupleType", "equals", "fail", "fail", "fail", "getSimpleName", "getClass", "getMessage"]}, "focal_class": {"identifier": "HadoopInputFormat", "superclass": "extends HadoopInputFormatBase<K, V, Tuple2<K, V>>", "interfaces": "implements ResultTypeQueryable<Tuple2<K,V>>", "fields": [{"original_string": "private static final long serialVersionUID = 1L;", "modifier": "private static final", "type": "long", "declarator": "serialVersionUID = 1L", "var_name": "serialVersionUID"}], "methods": [{"identifier": "HadoopInputFormat", "parameters": "(org.apache.hadoop.mapreduce.InputFormat<K,V> mapreduceInputFormat, Class<K> key, Class<V> value, Job job)", "modifiers": "public", "return": "", "signature": " HadoopInputFormat(org.apache.hadoop.mapreduce.InputFormat<K,V> mapreduceInputFormat, Class<K> key, Class<V> value, Job job)", "full_signature": "public  HadoopInputFormat(org.apache.hadoop.mapreduce.InputFormat<K,V> mapreduceInputFormat, Class<K> key, Class<V> value, Job job)", "class_method_signature": "HadoopInputFormat.HadoopInputFormat(org.apache.hadoop.mapreduce.InputFormat<K,V> mapreduceInputFormat, Class<K> key, Class<V> value, Job job)", "testcase": false, "constructor": true}, {"identifier": "HadoopInputFormat", "parameters": "(org.apache.hadoop.mapreduce.InputFormat<K,V> mapreduceInputFormat, Class<K> key, Class<V> value)", "modifiers": "public", "return": "", "signature": " HadoopInputFormat(org.apache.hadoop.mapreduce.InputFormat<K,V> mapreduceInputFormat, Class<K> key, Class<V> value)", "full_signature": "public  HadoopInputFormat(org.apache.hadoop.mapreduce.InputFormat<K,V> mapreduceInputFormat, Class<K> key, Class<V> value)", "class_method_signature": "HadoopInputFormat.HadoopInputFormat(org.apache.hadoop.mapreduce.InputFormat<K,V> mapreduceInputFormat, Class<K> key, Class<V> value)", "testcase": false, "constructor": true}, {"identifier": "nextRecord", "parameters": "(Tuple2<K, V> record)", "modifiers": "@Override public", "return": "Tuple2<K, V>", "signature": "Tuple2<K, V> nextRecord(Tuple2<K, V> record)", "full_signature": "@Override public Tuple2<K, V> nextRecord(Tuple2<K, V> record)", "class_method_signature": "HadoopInputFormat.nextRecord(Tuple2<K, V> record)", "testcase": false, "constructor": false}, {"identifier": "getProducedType", "parameters": "()", "modifiers": "@Override public", "return": "TypeInformation<Tuple2<K,V>>", "signature": "TypeInformation<Tuple2<K,V>> getProducedType()", "full_signature": "@Override public TypeInformation<Tuple2<K,V>> getProducedType()", "class_method_signature": "HadoopInputFormat.getProducedType()", "testcase": false, "constructor": false}], "file": "flink-java/src/main/java/org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormat.java"}, "focal_method": {"identifier": "getProducedType", "parameters": "()", "modifiers": "@Override public", "return": "TypeInformation<Tuple2<K,V>>", "body": "@Override\n\tpublic TypeInformation<Tuple2<K,V>> getProducedType() {\n\t\treturn new TupleTypeInfo<Tuple2<K,V>>(TypeExtractor.createTypeInfo(keyClass), TypeExtractor.createTypeInfo(valueClass));\n\t}", "signature": "TypeInformation<Tuple2<K,V>> getProducedType()", "full_signature": "@Override public TypeInformation<Tuple2<K,V>> getProducedType()", "class_method_signature": "HadoopInputFormat.getProducedType()", "testcase": false, "constructor": false, "invocations": ["createTypeInfo", "createTypeInfo"]}, "repository": {"repo_id": 47972099, "url": "https://github.com/streamline-eu/ML-Pipelines", "language": "Java", "is_fork": false, "fork_count": 7, "stargazer_count": 7, "size": 85537, "license": "licensed"}}