{"test_class": {"identifier": "AvroRecordReaderTest", "superclass": "", "interfaces": "", "fields": [{"original_string": "private static final int RECORD_COUNT = 50;", "modifier": "private static final", "type": "int", "declarator": "RECORD_COUNT = 50", "var_name": "RECORD_COUNT"}, {"original_string": "private static final int AUTO_SYNC_INTERVAL = 32;", "modifier": "private static final", "type": "int", "declarator": "AUTO_SYNC_INTERVAL = 32", "var_name": "AUTO_SYNC_INTERVAL"}, {"original_string": "@Rule\n  public TemporaryFolder temporaryFolder = new TemporaryFolder();", "modifier": "@Rule\n  public", "type": "TemporaryFolder", "declarator": "temporaryFolder = new TemporaryFolder()", "var_name": "temporaryFolder"}, {"original_string": "private File testAvroFile;", "modifier": "private", "type": "File", "declarator": "testAvroFile", "var_name": "testAvroFile"}, {"original_string": "private List<String> allAddedKeys;", "modifier": "private", "type": "List<String>", "declarator": "allAddedKeys", "var_name": "allAddedKeys"}], "file": "bigquery/src/test/java/com/google/cloud/hadoop/io/bigquery/AvroRecordReaderTest.java"}, "test_case": {"identifier": "testMultipleSplits", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n  public void testMultipleSplits() throws IOException {\n    long fileLength = testAvroFile.length();\n    List<FileSplit> splits = new ArrayList<>();\n    Path hadoopPath = new Path(\"file\", null,  testAvroFile.getAbsolutePath());\n\n    for (int blockStart = 0; blockStart < fileLength; blockStart += AUTO_SYNC_INTERVAL) {\n      splits.add(new FileSplit(hadoopPath, blockStart, AUTO_SYNC_INTERVAL, new String[0]));\n    }\n\n    List<String> allRecordKeys = new ArrayList<>();\n    long totalFileRecords = 0;\n    for (FileSplit split : splits) {\n      try (AvroRecordReader reader = new AvroRecordReader()) {\n        reader.initializeInternal(split, new Configuration());\n        List<String> keysInSplit = collectRecordKeys(reader);\n        allRecordKeys.addAll(keysInSplit);\n        int recordsInSplit = keysInSplit.size();\n        totalFileRecords += recordsInSplit;\n        // Not all 'blocks' contain records, but none should have all records\n        Truth.assertThat(recordsInSplit)\n            .isLessThan(RECORD_COUNT);\n      }\n    }\n\n    Truth.assertThat(allRecordKeys).containsExactlyElementsIn(allAddedKeys);\n    Truth.assertThat(totalFileRecords).isEqualTo(RECORD_COUNT);\n  }", "signature": "void testMultipleSplits()", "full_signature": "@Test public void testMultipleSplits()", "class_method_signature": "AvroRecordReaderTest.testMultipleSplits()", "testcase": true, "constructor": false, "invocations": ["length", "getAbsolutePath", "add", "initializeInternal", "collectRecordKeys", "addAll", "size", "isLessThan", "assertThat", "containsExactlyElementsIn", "assertThat", "isEqualTo", "assertThat"]}, "focal_class": {"identifier": "AvroRecordReader", "superclass": "extends RecordReader<LongWritable, GenericData.Record>", "interfaces": "", "fields": [{"original_string": "final LongWritable currentKey = new LongWritable();", "modifier": "final", "type": "LongWritable", "declarator": "currentKey = new LongWritable()", "var_name": "currentKey"}, {"original_string": "FileReader<GenericData.Record> dataFileReader;", "modifier": "", "type": "FileReader<GenericData.Record>", "declarator": "dataFileReader", "var_name": "dataFileReader"}, {"original_string": "Schema schema;", "modifier": "", "type": "Schema", "declarator": "schema", "var_name": "schema"}, {"original_string": "GenericData.Record currentRecord;", "modifier": "", "type": "GenericData.Record", "declarator": "currentRecord", "var_name": "currentRecord"}, {"original_string": "long inputFileLength;", "modifier": "", "type": "long", "declarator": "inputFileLength", "var_name": "inputFileLength"}, {"original_string": "long splitStart;", "modifier": "", "type": "long", "declarator": "splitStart", "var_name": "splitStart"}, {"original_string": "long splitLength;", "modifier": "", "type": "long", "declarator": "splitLength", "var_name": "splitLength"}], "methods": [{"identifier": "initialize", "parameters": "(InputSplit inputSplit, TaskAttemptContext taskAttemptContext)", "modifiers": "@Override public", "return": "void", "signature": "void initialize(InputSplit inputSplit, TaskAttemptContext taskAttemptContext)", "full_signature": "@Override public void initialize(InputSplit inputSplit, TaskAttemptContext taskAttemptContext)", "class_method_signature": "AvroRecordReader.initialize(InputSplit inputSplit, TaskAttemptContext taskAttemptContext)", "testcase": false, "constructor": false}, {"identifier": "initializeInternal", "parameters": "(InputSplit inputSplit, Configuration conf)", "modifiers": "protected", "return": "void", "signature": "void initializeInternal(InputSplit inputSplit, Configuration conf)", "full_signature": "protected void initializeInternal(InputSplit inputSplit, Configuration conf)", "class_method_signature": "AvroRecordReader.initializeInternal(InputSplit inputSplit, Configuration conf)", "testcase": false, "constructor": false}, {"identifier": "nextKeyValue", "parameters": "()", "modifiers": "@Override public", "return": "boolean", "signature": "boolean nextKeyValue()", "full_signature": "@Override public boolean nextKeyValue()", "class_method_signature": "AvroRecordReader.nextKeyValue()", "testcase": false, "constructor": false}, {"identifier": "getCurrentKey", "parameters": "()", "modifiers": "@Override public", "return": "LongWritable", "signature": "LongWritable getCurrentKey()", "full_signature": "@Override public LongWritable getCurrentKey()", "class_method_signature": "AvroRecordReader.getCurrentKey()", "testcase": false, "constructor": false}, {"identifier": "getCurrentValue", "parameters": "()", "modifiers": "@Override public", "return": "GenericData.Record", "signature": "GenericData.Record getCurrentValue()", "full_signature": "@Override public GenericData.Record getCurrentValue()", "class_method_signature": "AvroRecordReader.getCurrentValue()", "testcase": false, "constructor": false}, {"identifier": "getProgress", "parameters": "()", "modifiers": "@Override public", "return": "float", "signature": "float getProgress()", "full_signature": "@Override public float getProgress()", "class_method_signature": "AvroRecordReader.getProgress()", "testcase": false, "constructor": false}, {"identifier": "close", "parameters": "()", "modifiers": "@Override public", "return": "void", "signature": "void close()", "full_signature": "@Override public void close()", "class_method_signature": "AvroRecordReader.close()", "testcase": false, "constructor": false}], "file": "bigquery/src/main/java/com/google/cloud/hadoop/io/bigquery/AvroRecordReader.java"}, "focal_method": {"identifier": "initializeInternal", "parameters": "(InputSplit inputSplit, Configuration conf)", "modifiers": "protected", "return": "void", "body": "protected void initializeInternal(InputSplit inputSplit, Configuration conf) throws IOException {\n    Preconditions.checkState(\n        inputSplit instanceof FileSplit, \"AvroRecordReader requires FileSplit input splits.\");\n    FileSplit fileSplit = (FileSplit) inputSplit;\n    splitStart = fileSplit.getStart();\n    splitLength = fileSplit.getLength();\n\n    Path filePath = fileSplit.getPath();\n    FileSystem fs = filePath.getFileSystem(conf);\n    FileStatus status = fs.getFileStatus(filePath);\n    inputFileLength = status.getLen();\n\n    final FSDataInputStream stream = fs.open(filePath);\n    dataFileReader =\n        DataFileReader.openReader(\n            new SeekableInput() {\n              @Override\n              public void seek(long offset) throws IOException {\n                stream.seek(offset);\n              }\n\n              @Override\n              public long tell() throws IOException {\n                return stream.getPos();\n              }\n\n              @Override\n              public long length() {\n                return inputFileLength;\n              }\n\n              @Override\n              public int read(byte[] bytes, int offset, int length) throws IOException {\n                return stream.read(bytes, offset, length);\n              }\n\n              @Override\n              public void close() throws IOException {\n                stream.close();\n              }\n            },\n            new GenericDatumReader<GenericData.Record>());\n    // Sync to the first sync point after the start of the split:\n    dataFileReader.sync(fileSplit.getStart());\n    schema = dataFileReader.getSchema();\n    currentRecord = new GenericData.Record(schema);\n  }", "signature": "void initializeInternal(InputSplit inputSplit, Configuration conf)", "full_signature": "protected void initializeInternal(InputSplit inputSplit, Configuration conf)", "class_method_signature": "AvroRecordReader.initializeInternal(InputSplit inputSplit, Configuration conf)", "testcase": false, "constructor": false, "invocations": ["checkState", "getStart", "getLength", "getPath", "getFileSystem", "getFileStatus", "getLen", "open", "openReader", "seek", "getPos", "read", "close", "sync", "getStart", "getSchema"]}, "repository": {"repo_id": 19684359, "url": "https://github.com/GoogleCloudDataproc/bigdata-interop", "stars": 178, "created": "5/12/2014 3:11:55 AM +00:00", "updates": "2020-01-23T23:10:40+00:00", "fork": "False", "license": "licensed"}}