{"test_class": {"identifier": "GaussianNaiveBayesTrainerTest", "superclass": "extends TrainerTest", "interfaces": "", "fields": [{"original_string": "private static final double PRECISION = 1e-2;", "modifier": "private static final", "type": "double", "declarator": "PRECISION = 1e-2", "var_name": "PRECISION"}, {"original_string": "private static final double LABEL_1 = 1.;", "modifier": "private static final", "type": "double", "declarator": "LABEL_1 = 1.", "var_name": "LABEL_1"}, {"original_string": "private static final double LABEL_2 = 2.;", "modifier": "private static final", "type": "double", "declarator": "LABEL_2 = 2.", "var_name": "LABEL_2"}, {"original_string": "private static final Map<Integer, double[]> data = new HashMap<>();", "modifier": "private static final", "type": "Map<Integer, double[]>", "declarator": "data = new HashMap<>()", "var_name": "data"}, {"original_string": "private static final Map<Integer, double[]> singleLabeldata1 = new HashMap<>();", "modifier": "private static final", "type": "Map<Integer, double[]>", "declarator": "singleLabeldata1 = new HashMap<>()", "var_name": "singleLabeldata1"}, {"original_string": "private static final Map<Integer, double[]> singleLabeldata2 = new HashMap<>();", "modifier": "private static final", "type": "Map<Integer, double[]>", "declarator": "singleLabeldata2 = new HashMap<>()", "var_name": "singleLabeldata2"}, {"original_string": "private GaussianNaiveBayesTrainer trainer;", "modifier": "private", "type": "GaussianNaiveBayesTrainer", "declarator": "trainer", "var_name": "trainer"}], "file": "modules/ml/src/test/java/org/apache/ignite/ml/naivebayes/gaussian/GaussianNaiveBayesTrainerTest.java"}, "test_case": {"identifier": "testUpdatigModel", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n    public void testUpdatigModel() {\n        Vectorizer<Integer, double[], Integer, Double> vectorizer = new DoubleArrayVectorizer<Integer>().labeled(Vectorizer.LabelCoordinate.LAST);\n        GaussianNaiveBayesModel model = trainer.fit(\n            new LocalDatasetBuilder<>(singleLabeldata1, parts),\n            vectorizer\n        );\n\n        GaussianNaiveBayesModel updatedModel = trainer.updateModel(model,\n            new LocalDatasetBuilder<>(singleLabeldata2, parts),\n            vectorizer\n        );\n\n        Assert.assertEquals(3. / data.size(), updatedModel.getClassProbabilities()[0], PRECISION);\n        Assert.assertEquals(2. / data.size(), updatedModel.getClassProbabilities()[1], PRECISION);\n    }", "signature": "void testUpdatigModel()", "full_signature": "@Test public void testUpdatigModel()", "class_method_signature": "GaussianNaiveBayesTrainerTest.testUpdatigModel()", "testcase": true, "constructor": false, "invocations": ["labeled", "fit", "updateModel", "assertEquals", "size", "getClassProbabilities", "assertEquals", "size", "getClassProbabilities"]}, "focal_class": {"identifier": "GaussianNaiveBayesTrainer", "superclass": "extends SingleLabelDatasetTrainer<GaussianNaiveBayesModel>", "interfaces": "", "fields": [{"original_string": "private double[] priorProbabilities;", "modifier": "private", "type": "double[]", "declarator": "priorProbabilities", "var_name": "priorProbabilities"}, {"original_string": "private boolean equiprobableClasses;", "modifier": "private", "type": "boolean", "declarator": "equiprobableClasses", "var_name": "equiprobableClasses"}], "methods": [{"identifier": "fitWithInitializedDeployingContext", "parameters": "(DatasetBuilder<K, V> datasetBuilder,\n                                                        Preprocessor<K, V> extractor)", "modifiers": "@Override public", "return": "GaussianNaiveBayesModel", "signature": "GaussianNaiveBayesModel fitWithInitializedDeployingContext(DatasetBuilder<K, V> datasetBuilder,\n                                                        Preprocessor<K, V> extractor)", "full_signature": "@Override public GaussianNaiveBayesModel fitWithInitializedDeployingContext(DatasetBuilder<K, V> datasetBuilder,\n                                                        Preprocessor<K, V> extractor)", "class_method_signature": "GaussianNaiveBayesTrainer.fitWithInitializedDeployingContext(DatasetBuilder<K, V> datasetBuilder,\n                                                        Preprocessor<K, V> extractor)", "testcase": false, "constructor": false}, {"identifier": "isUpdateable", "parameters": "(GaussianNaiveBayesModel mdl)", "modifiers": "@Override public", "return": "boolean", "signature": "boolean isUpdateable(GaussianNaiveBayesModel mdl)", "full_signature": "@Override public boolean isUpdateable(GaussianNaiveBayesModel mdl)", "class_method_signature": "GaussianNaiveBayesTrainer.isUpdateable(GaussianNaiveBayesModel mdl)", "testcase": false, "constructor": false}, {"identifier": "withEnvironmentBuilder", "parameters": "(LearningEnvironmentBuilder envBuilder)", "modifiers": "@Override public", "return": "GaussianNaiveBayesTrainer", "signature": "GaussianNaiveBayesTrainer withEnvironmentBuilder(LearningEnvironmentBuilder envBuilder)", "full_signature": "@Override public GaussianNaiveBayesTrainer withEnvironmentBuilder(LearningEnvironmentBuilder envBuilder)", "class_method_signature": "GaussianNaiveBayesTrainer.withEnvironmentBuilder(LearningEnvironmentBuilder envBuilder)", "testcase": false, "constructor": false}, {"identifier": "updateModel", "parameters": "(GaussianNaiveBayesModel mdl,\n                                                                   DatasetBuilder<K, V> datasetBuilder, Preprocessor<K, V> extractor)", "modifiers": "@Override protected", "return": "GaussianNaiveBayesModel", "signature": "GaussianNaiveBayesModel updateModel(GaussianNaiveBayesModel mdl,\n                                                                   DatasetBuilder<K, V> datasetBuilder, Preprocessor<K, V> extractor)", "full_signature": "@Override protected GaussianNaiveBayesModel updateModel(GaussianNaiveBayesModel mdl,\n                                                                   DatasetBuilder<K, V> datasetBuilder, Preprocessor<K, V> extractor)", "class_method_signature": "GaussianNaiveBayesTrainer.updateModel(GaussianNaiveBayesModel mdl,\n                                                                   DatasetBuilder<K, V> datasetBuilder, Preprocessor<K, V> extractor)", "testcase": false, "constructor": false}, {"identifier": "withEquiprobableClasses", "parameters": "()", "modifiers": "public", "return": "GaussianNaiveBayesTrainer", "signature": "GaussianNaiveBayesTrainer withEquiprobableClasses()", "full_signature": "public GaussianNaiveBayesTrainer withEquiprobableClasses()", "class_method_signature": "GaussianNaiveBayesTrainer.withEquiprobableClasses()", "testcase": false, "constructor": false}, {"identifier": "setPriorProbabilities", "parameters": "(double[] priorProbabilities)", "modifiers": "public", "return": "GaussianNaiveBayesTrainer", "signature": "GaussianNaiveBayesTrainer setPriorProbabilities(double[] priorProbabilities)", "full_signature": "public GaussianNaiveBayesTrainer setPriorProbabilities(double[] priorProbabilities)", "class_method_signature": "GaussianNaiveBayesTrainer.setPriorProbabilities(double[] priorProbabilities)", "testcase": false, "constructor": false}, {"identifier": "resetSettings", "parameters": "()", "modifiers": "public", "return": "GaussianNaiveBayesTrainer", "signature": "GaussianNaiveBayesTrainer resetSettings()", "full_signature": "public GaussianNaiveBayesTrainer resetSettings()", "class_method_signature": "GaussianNaiveBayesTrainer.resetSettings()", "testcase": false, "constructor": false}], "file": "modules/ml/src/main/java/org/apache/ignite/ml/naivebayes/gaussian/GaussianNaiveBayesTrainer.java"}, "focal_method": {"identifier": "updateModel", "parameters": "(GaussianNaiveBayesModel mdl,\n                                                                   DatasetBuilder<K, V> datasetBuilder, Preprocessor<K, V> extractor)", "modifiers": "@Override protected", "return": "GaussianNaiveBayesModel", "body": "@Override protected <K, V> GaussianNaiveBayesModel updateModel(GaussianNaiveBayesModel mdl,\n                                                                   DatasetBuilder<K, V> datasetBuilder, Preprocessor<K, V> extractor) {\n        assert datasetBuilder != null;\n\n        try (Dataset<EmptyContext, GaussianNaiveBayesSumsHolder> dataset = datasetBuilder.build(\n            envBuilder,\n            (env, upstream, upstreamSize) -> new EmptyContext(),\n            (env, upstream, upstreamSize, ctx) -> {\n\n                GaussianNaiveBayesSumsHolder res = new GaussianNaiveBayesSumsHolder();\n                while (upstream.hasNext()) {\n                    UpstreamEntry<K, V> entity = upstream.next();\n\n                    LabeledVector lv = extractor.apply(entity.getKey(), entity.getValue());\n                    Vector features = lv.features();\n                    Double label = (Double) lv.label();\n\n                    double[] toMeans;\n                    double[] sqSum;\n\n                    if (!res.featureSumsPerLbl.containsKey(label)) {\n                        toMeans = new double[features.size()];\n                        Arrays.fill(toMeans, 0.);\n                        res.featureSumsPerLbl.put(label, toMeans);\n                    }\n                    if (!res.featureSquaredSumsPerLbl.containsKey(label)) {\n                        sqSum = new double[features.size()];\n                        res.featureSquaredSumsPerLbl.put(label, sqSum);\n                    }\n                    if (!res.featureCountersPerLbl.containsKey(label))\n                        res.featureCountersPerLbl.put(label, 0);\n\n                    res.featureCountersPerLbl.put(label, res.featureCountersPerLbl.get(label) + 1);\n\n                    toMeans = res.featureSumsPerLbl.get(label);\n                    sqSum = res.featureSquaredSumsPerLbl.get(label);\n                    for (int j = 0; j < features.size(); j++) {\n                        double x = features.get(j);\n                        toMeans[j] += x;\n                        sqSum[j] += x * x;\n                    }\n                }\n                return res;\n            }, learningEnvironment()\n        )) {\n            GaussianNaiveBayesSumsHolder sumsHolder = dataset.compute(t -> t, (a, b) -> {\n                if (a == null)\n                    return b == null ? new GaussianNaiveBayesSumsHolder() : b;\n                if (b == null)\n                    return a;\n                return a.merge(b);\n            });\n            if (mdl != null && mdl.getSumsHolder() != null)\n                sumsHolder = sumsHolder.merge(mdl.getSumsHolder());\n\n            List<Double> sortedLabels = new ArrayList<>(sumsHolder.featureCountersPerLbl.keySet());\n            sortedLabels.sort(Double::compareTo);\n            assert !sortedLabels.isEmpty() : \"The dataset should contain at least one feature\";\n\n            int labelCount = sortedLabels.size();\n            int featureCount = sumsHolder.featureSumsPerLbl.get(sortedLabels.get(0)).length;\n\n            double[][] means = new double[labelCount][featureCount];\n            double[][] variances = new double[labelCount][featureCount];\n            double[] classProbabilities = new double[labelCount];\n            double[] labels = new double[labelCount];\n\n            long datasetSize = sumsHolder.featureCountersPerLbl.values().stream().mapToInt(i -> i).sum();\n\n            int lbl = 0;\n            for (Double label : sortedLabels) {\n                int count = sumsHolder.featureCountersPerLbl.get(label);\n                double[] sum = sumsHolder.featureSumsPerLbl.get(label);\n                double[] sqSum = sumsHolder.featureSquaredSumsPerLbl.get(label);\n\n                for (int i = 0; i < featureCount; i++) {\n                    means[lbl][i] = sum[i] / count;\n                    variances[lbl][i] = (sqSum[i] - sum[i] * sum[i] / count) / count;\n                }\n\n                if (equiprobableClasses)\n                    classProbabilities[lbl] = 1. / labelCount;\n\n                else if (priorProbabilities != null) {\n                    assert classProbabilities.length == priorProbabilities.length;\n                    classProbabilities[lbl] = priorProbabilities[lbl];\n                }\n                else\n                    classProbabilities[lbl] = (double)count / datasetSize;\n\n                labels[lbl] = label;\n                ++lbl;\n            }\n\n            return new GaussianNaiveBayesModel(means, variances, classProbabilities, labels, sumsHolder);\n        }\n        catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n\n    }", "signature": "GaussianNaiveBayesModel updateModel(GaussianNaiveBayesModel mdl,\n                                                                   DatasetBuilder<K, V> datasetBuilder, Preprocessor<K, V> extractor)", "full_signature": "@Override protected GaussianNaiveBayesModel updateModel(GaussianNaiveBayesModel mdl,\n                                                                   DatasetBuilder<K, V> datasetBuilder, Preprocessor<K, V> extractor)", "class_method_signature": "GaussianNaiveBayesTrainer.updateModel(GaussianNaiveBayesModel mdl,\n                                                                   DatasetBuilder<K, V> datasetBuilder, Preprocessor<K, V> extractor)", "testcase": false, "constructor": false, "invocations": ["build", "hasNext", "next", "apply", "getKey", "getValue", "features", "label", "containsKey", "size", "fill", "put", "containsKey", "size", "put", "containsKey", "put", "put", "get", "get", "get", "size", "get", "learningEnvironment", "compute", "merge", "getSumsHolder", "merge", "getSumsHolder", "keySet", "sort", "isEmpty", "size", "get", "get", "sum", "mapToInt", "stream", "values", "get", "get", "get"]}, "repository": {"repo_id": 170496871, "url": "https://github.com/gridgain/gridgain", "stars": 46, "created": "2/13/2019 11:31:35 AM +00:00", "updates": "2020-01-27T16:02:24+00:00", "fork": "False", "license": "licensed"}}