{"test_class": {"identifier": "TwitterTokenizerTest", "superclass": "", "interfaces": "", "fields": [], "file": "storm/trident-ml/src/test/java/com/github/pmerienne/trident/ml/preprocessing/TwitterTokenizerTest.java"}, "test_case": {"identifier": "testRemoveUsername", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n\tpublic void testRemoveUsername() {\n\t\t// Given\n\t\tString tweet = \"@PrincessSuperC Hey Cici\";\n\t\tTwitterTokenizer tokenizer = new TwitterTokenizer();\n\n\t\t// When\n\t\tList<String> actualTokens = tokenizer.tokenize(tweet);\n\n\t\t// Then\n\t\tList<String> expectedTokens = Arrays.asList(\"hei\", \"cici\");\n\t\tassertEquals(expectedTokens, actualTokens);\n\t}", "signature": "void testRemoveUsername()", "full_signature": "@Test public void testRemoveUsername()", "class_method_signature": "TwitterTokenizerTest.testRemoveUsername()", "testcase": true, "constructor": false, "invocations": ["tokenize", "asList", "assertEquals"]}, "focal_class": {"identifier": "TwitterTokenizer", "superclass": "extends EnglishTokenizer", "interfaces": "", "fields": [{"original_string": "private static final long serialVersionUID = -2486285775626564821L;", "modifier": "private static final", "type": "long", "declarator": "serialVersionUID = -2486285775626564821L", "var_name": "serialVersionUID"}, {"original_string": "private final static String URL_REGEX = \"((www\\\\.[\\\\s]+)|(https?://[^\\\\s]+))\";", "modifier": "private final static", "type": "String", "declarator": "URL_REGEX = \"((www\\\\.[\\\\s]+)|(https?://[^\\\\s]+))\"", "var_name": "URL_REGEX"}, {"original_string": "private final static String CONSECUTIVE_CHARS = \"([a-z])\\\\1{1,}\";", "modifier": "private final static", "type": "String", "declarator": "CONSECUTIVE_CHARS = \"([a-z])\\\\1{1,}\"", "var_name": "CONSECUTIVE_CHARS"}, {"original_string": "private final static String STARTS_WITH_NUMBER = \"[1-9]\\\\s*(\\\\w+)\";", "modifier": "private final static", "type": "String", "declarator": "STARTS_WITH_NUMBER = \"[1-9]\\\\s*(\\\\w+)\"", "var_name": "STARTS_WITH_NUMBER"}], "methods": [{"identifier": "TwitterTokenizer", "parameters": "()", "modifiers": "public", "return": "", "signature": " TwitterTokenizer()", "full_signature": "public  TwitterTokenizer()", "class_method_signature": "TwitterTokenizer.TwitterTokenizer()", "testcase": false, "constructor": true}, {"identifier": "TwitterTokenizer", "parameters": "(int minNGram, int maxNGram)", "modifiers": "public", "return": "", "signature": " TwitterTokenizer(int minNGram, int maxNGram)", "full_signature": "public  TwitterTokenizer(int minNGram, int maxNGram)", "class_method_signature": "TwitterTokenizer.TwitterTokenizer(int minNGram, int maxNGram)", "testcase": false, "constructor": true}, {"identifier": "tokenize", "parameters": "(String text)", "modifiers": "@Override public", "return": "List<String>", "signature": "List<String> tokenize(String text)", "full_signature": "@Override public List<String> tokenize(String text)", "class_method_signature": "TwitterTokenizer.tokenize(String text)", "testcase": false, "constructor": false}, {"identifier": "preprocess", "parameters": "(String tweet)", "modifiers": "protected", "return": "String", "signature": "String preprocess(String tweet)", "full_signature": "protected String preprocess(String tweet)", "class_method_signature": "TwitterTokenizer.preprocess(String tweet)", "testcase": false, "constructor": false}], "file": "storm/trident-ml/src/main/java/com/github/pmerienne/trident/ml/preprocessing/TwitterTokenizer.java"}, "focal_method": {"identifier": "tokenize", "parameters": "(String text)", "modifiers": "@Override public", "return": "List<String>", "body": "@Override\n\tpublic List<String> tokenize(String text) {\n\t\ttext = this.preprocess(text);\n\t\treturn super.tokenize(text);\n\t}", "signature": "List<String> tokenize(String text)", "full_signature": "@Override public List<String> tokenize(String text)", "class_method_signature": "TwitterTokenizer.tokenize(String text)", "testcase": false, "constructor": false, "invocations": ["preprocess", "tokenize"]}, "repository": {"repo_id": 44512524, "url": "https://github.com/zqhxuyuan/bigdata", "language": "Java", "is_fork": false, "fork_count": 6, "stargazer_count": 8, "size": 91550, "license": "licensed"}}