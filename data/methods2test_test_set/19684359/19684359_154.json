{"test_class": {"identifier": "FederatedBigQueryOutputCommitterTest", "superclass": "", "interfaces": "", "fields": [{"original_string": "private static final String TEST_PROJECT_ID = \"domain:project\";", "modifier": "private static final", "type": "String", "declarator": "TEST_PROJECT_ID = \"domain:project\"", "var_name": "TEST_PROJECT_ID"}, {"original_string": "private static final String TEST_DATASET_ID = \"dataset\";", "modifier": "private static final", "type": "String", "declarator": "TEST_DATASET_ID = \"dataset\"", "var_name": "TEST_DATASET_ID"}, {"original_string": "private static final String TEST_TABLE_ID = \"table\";", "modifier": "private static final", "type": "String", "declarator": "TEST_TABLE_ID = \"table\"", "var_name": "TEST_TABLE_ID"}, {"original_string": "private static final String QUALIFIED_TEST_TABLE_ID =\n      String.format(\"%s:%s.%s\", TEST_PROJECT_ID, TEST_DATASET_ID, TEST_TABLE_ID);", "modifier": "private static final", "type": "String", "declarator": "QUALIFIED_TEST_TABLE_ID =\n      String.format(\"%s:%s.%s\", TEST_PROJECT_ID, TEST_DATASET_ID, TEST_TABLE_ID)", "var_name": "QUALIFIED_TEST_TABLE_ID"}, {"original_string": "private static final BigQueryFileFormat TEST_FILE_FORMAT =\n      BigQueryFileFormat.NEWLINE_DELIMITED_JSON;", "modifier": "private static final", "type": "BigQueryFileFormat", "declarator": "TEST_FILE_FORMAT =\n      BigQueryFileFormat.NEWLINE_DELIMITED_JSON", "var_name": "TEST_FILE_FORMAT"}, {"original_string": "@SuppressWarnings(\"rawtypes\")\n  private static final Class<? extends FileOutputFormat> TEST_OUTPUT_CLASS = TextOutputFormat.class;", "modifier": "@SuppressWarnings(\"rawtypes\")\n  private static final", "type": "Class<? extends FileOutputFormat>", "declarator": "TEST_OUTPUT_CLASS = TextOutputFormat.class", "var_name": "TEST_OUTPUT_CLASS"}, {"original_string": "private static final BigQueryTableSchema TEST_TABLE_SCHEMA =\n      BigQueryTableSchema.wrap(\n          new TableSchema()\n              .setFields(\n                  ImmutableList.of(\n                      new TableFieldSchema().setName(\"Word\").setType(\"STRING\"),\n                      new TableFieldSchema().setName(\"Count\").setType(\"INTEGER\"))));", "modifier": "private static final", "type": "BigQueryTableSchema", "declarator": "TEST_TABLE_SCHEMA =\n      BigQueryTableSchema.wrap(\n          new TableSchema()\n              .setFields(\n                  ImmutableList.of(\n                      new TableFieldSchema().setName(\"Word\").setType(\"STRING\"),\n                      new TableFieldSchema().setName(\"Count\").setType(\"INTEGER\"))))", "var_name": "TEST_TABLE_SCHEMA"}, {"original_string": "private static final TaskAttemptID TEST_TASK_ATTEMPT_ID =\n      new TaskAttemptID(new TaskID(\"sample_task\", 100, false, 200), 1);", "modifier": "private static final", "type": "TaskAttemptID", "declarator": "TEST_TASK_ATTEMPT_ID =\n      new TaskAttemptID(new TaskID(\"sample_task\", 100, false, 200), 1)", "var_name": "TEST_TASK_ATTEMPT_ID"}, {"original_string": "private static final String TEST_OUTPUT_PATH_STRING = \"gs://test_bucket/test_directory/\";", "modifier": "private static final", "type": "String", "declarator": "TEST_OUTPUT_PATH_STRING = \"gs://test_bucket/test_directory/\"", "var_name": "TEST_OUTPUT_PATH_STRING"}, {"original_string": "private static final String TEST_OUTPUT_FILE_STRING = TEST_OUTPUT_PATH_STRING + \"test_file\";", "modifier": "private static final", "type": "String", "declarator": "TEST_OUTPUT_FILE_STRING = TEST_OUTPUT_PATH_STRING + \"test_file\"", "var_name": "TEST_OUTPUT_FILE_STRING"}, {"original_string": "private InMemoryGoogleHadoopFileSystem ghfs;", "modifier": "private", "type": "InMemoryGoogleHadoopFileSystem", "declarator": "ghfs", "var_name": "ghfs"}, {"original_string": "private TableReference outputTableRef;", "modifier": "private", "type": "TableReference", "declarator": "outputTableRef", "var_name": "outputTableRef"}, {"original_string": "private Configuration conf;", "modifier": "private", "type": "Configuration", "declarator": "conf", "var_name": "conf"}, {"original_string": "private Path outputPath;", "modifier": "private", "type": "Path", "declarator": "outputPath", "var_name": "outputPath"}, {"original_string": "private Path outputSampleFilePath;", "modifier": "private", "type": "Path", "declarator": "outputSampleFilePath", "var_name": "outputSampleFilePath"}, {"original_string": "private Job job;", "modifier": "private", "type": "Job", "declarator": "job", "var_name": "job"}, {"original_string": "private FederatedBigQueryOutputCommitter committer;", "modifier": "private", "type": "FederatedBigQueryOutputCommitter", "declarator": "committer", "var_name": "committer"}, {"original_string": "@Mock private BigQueryHelper mockBigQueryHelper;", "modifier": "@Mock private", "type": "BigQueryHelper", "declarator": "mockBigQueryHelper", "var_name": "mockBigQueryHelper"}, {"original_string": "@Mock private TaskAttemptContext mockTaskAttemptContext;", "modifier": "@Mock private", "type": "TaskAttemptContext", "declarator": "mockTaskAttemptContext", "var_name": "mockTaskAttemptContext"}, {"original_string": "@Mock private OutputCommitter mockCommitter;", "modifier": "@Mock private", "type": "OutputCommitter", "declarator": "mockCommitter", "var_name": "mockCommitter"}], "file": "bigquery/src/test/java/com/google/cloud/hadoop/io/bigquery/output/FederatedBigQueryOutputCommitterTest.java"}, "test_case": {"identifier": "testCommitJob", "parameters": "()", "modifiers": "@Test public", "return": "void", "body": "@Test\n  public void testCommitJob() throws IOException {\n    // Setup the sample directory.\n    generateSampleFiles();\n\n    committer.commitJob(job);\n\n    // Setup a captor for the GCS paths argument\n    @SuppressWarnings({\"rawtypes\", \"unchecked\", \"cast\"})\n    // Class<List> is neither a sub/supertype of Class<List<String>>, the latter doesn't even exist.\n    Class<List<String>> listClass = (Class<List<String>>) (Class) List.class;\n    ArgumentCaptor<List<String>> gcsOutputFileCaptor = ArgumentCaptor.forClass(listClass);\n\n    // Verify we're making the BigQuery import call.\n    verify(mockBigQueryHelper)\n        .importFederatedFromGcs(\n            eq(TEST_PROJECT_ID),\n            eq(outputTableRef),\n            eq(TEST_TABLE_SCHEMA.get()),\n            eq(TEST_FILE_FORMAT),\n            gcsOutputFileCaptor.capture());\n\n    // Verify the delegate is being called.\n    verify(mockCommitter).commitJob(eq(job));\n\n    // Assert the passed files contains our sample file.\n    assertThat(gcsOutputFileCaptor.getValue()).containsExactly(TEST_OUTPUT_FILE_STRING);\n  }", "signature": "void testCommitJob()", "full_signature": "@Test public void testCommitJob()", "class_method_signature": "FederatedBigQueryOutputCommitterTest.testCommitJob()", "testcase": true, "constructor": false, "invocations": ["generateSampleFiles", "commitJob", "forClass", "importFederatedFromGcs", "verify", "eq", "eq", "eq", "get", "eq", "capture", "commitJob", "verify", "eq", "containsExactly", "assertThat", "getValue"]}, "focal_class": {"identifier": "FederatedBigQueryOutputCommitter", "superclass": "extends ForwardingBigQueryFileOutputCommitter", "interfaces": "", "fields": [], "methods": [{"identifier": "FederatedBigQueryOutputCommitter", "parameters": "(TaskAttemptContext context, OutputCommitter delegate)", "modifiers": "public", "return": "", "signature": " FederatedBigQueryOutputCommitter(TaskAttemptContext context, OutputCommitter delegate)", "full_signature": "public  FederatedBigQueryOutputCommitter(TaskAttemptContext context, OutputCommitter delegate)", "class_method_signature": "FederatedBigQueryOutputCommitter.FederatedBigQueryOutputCommitter(TaskAttemptContext context, OutputCommitter delegate)", "testcase": false, "constructor": true}, {"identifier": "commitJob", "parameters": "(JobContext context)", "modifiers": "@Override public", "return": "void", "signature": "void commitJob(JobContext context)", "full_signature": "@Override public void commitJob(JobContext context)", "class_method_signature": "FederatedBigQueryOutputCommitter.commitJob(JobContext context)", "testcase": false, "constructor": false}, {"identifier": "abortJob", "parameters": "(JobContext context, State state)", "modifiers": "@Override public", "return": "void", "signature": "void abortJob(JobContext context, State state)", "full_signature": "@Override public void abortJob(JobContext context, State state)", "class_method_signature": "FederatedBigQueryOutputCommitter.abortJob(JobContext context, State state)", "testcase": false, "constructor": false}], "file": "bigquery/src/main/java/com/google/cloud/hadoop/io/bigquery/output/FederatedBigQueryOutputCommitter.java"}, "focal_method": {"identifier": "commitJob", "parameters": "(JobContext context)", "modifiers": "@Override public", "return": "void", "body": "@Override\n  public void commitJob(JobContext context) throws IOException {\n    super.commitJob(context);\n\n    // Get the destination configuration information.\n    Configuration conf = context.getConfiguration();\n    TableReference destTable = BigQueryOutputConfiguration.getTableReference(conf);\n    String jobProjectId = BigQueryOutputConfiguration.getJobProjectId(conf);\n    Optional<BigQueryTableSchema> destSchema = BigQueryOutputConfiguration.getTableSchema(conf);\n    BigQueryFileFormat outputFileFormat = BigQueryOutputConfiguration.getFileFormat(conf);\n    List<String> sourceUris = getOutputFileURIs();\n\n    getBigQueryHelper()\n        .importFederatedFromGcs(\n            jobProjectId,\n            destTable,\n            destSchema.isPresent() ? destSchema.get().get() : null,\n            outputFileFormat,\n            sourceUris);\n  }", "signature": "void commitJob(JobContext context)", "full_signature": "@Override public void commitJob(JobContext context)", "class_method_signature": "FederatedBigQueryOutputCommitter.commitJob(JobContext context)", "testcase": false, "constructor": false, "invocations": ["commitJob", "getConfiguration", "getTableReference", "getJobProjectId", "getTableSchema", "getFileFormat", "getOutputFileURIs", "importFederatedFromGcs", "getBigQueryHelper", "isPresent", "get", "get"]}, "repository": {"repo_id": 19684359, "url": "https://github.com/GoogleCloudDataproc/bigdata-interop", "stars": 178, "created": "5/12/2014 3:11:55 AM +00:00", "updates": "2020-01-23T23:10:40+00:00", "fork": "False", "license": "licensed"}}